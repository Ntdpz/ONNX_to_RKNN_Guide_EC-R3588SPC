# ü§ñ AI Assistant Context - ONNX to RKNN Conversion for Rockchip NPU

> **‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:** Copy ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏ß‡∏≤‡∏á‡πÉ‡∏ô System Prompt ‡∏´‡∏£‡∏∑‡∏≠ Context ‡∏Ç‡∏≠‡∏á AI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

---

## üìå ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£

‡πÄ‡∏õ‡πá‡∏ô Toolkit ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á AI Model (ONNX) ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô RKNN Format ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡∏ö‡∏ô Rockchip NPU (RK3588) ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏≠‡∏£‡πå‡∏î EC-R3588SPC

## üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏´‡∏•‡∏±‡∏Å

- ‡πÅ‡∏õ‡∏•‡∏á ONNX Model ‚Üí RKNN Model (FP16/INT8)
- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö YOLOv5, YOLOv8, YOLOv10, ‡πÅ‡∏•‡∏∞ Custom Models
- ‡∏ó‡∏≥ Quantization (INT8) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á Preprocessing ‡πÅ‡∏•‡∏∞ Postprocessing

---

## üîß ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏´‡∏•‡∏±‡∏Å

| Component | Version/Detail |
|-----------|----------------|
| **SDK** | RKNN-Toolkit2 v2.3.2 |
| **Platform** | RK3588 (6 TOPS NPU), ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö RK3576, RK3566, RK3568 |
| **Python** | 3.8+ |
| **ONNX Opset** | ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 12-19 (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 12) |

---

## üìÅ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Repository

```
ONNX_to_RKNN_Guide_EC-R3588SPC/
‚îú‚îÄ‚îÄ Data-set/                    # Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö INT8 Quantization
‚îÇ   ‚îî‚îÄ‚îÄ create_dataset_txt.py    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset.txt
‚îÇ
‚îú‚îÄ‚îÄ Doc/                         # ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
‚îÇ   ‚îú‚îÄ‚îÄ Custom_Model_to_RKNN_Guide_v2.3.0.md   # ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ Custom Model (v2.3.0)
‚îÇ   ‚îú‚îÄ‚îÄ Custom_Model_to_RKNN_Guide_v2.3.2.md   # ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ Custom Model (v2.3.2)
‚îÇ   ‚îú‚îÄ‚îÄ PREPROCESSING_POSTPROCESSING_GUIDE.md  # ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ Pre/Post processing
‚îÇ   ‚îî‚îÄ‚îÄ UNIVERSAL_CONVERTER_GUIDE.md           # ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ Converter
‚îÇ
‚îú‚îÄ‚îÄ Model-AI/                    # ‡πÄ‡∏Å‡πá‡∏ö Model (ONNX, RKNN)
‚îÇ   ‚îî‚îÄ‚îÄ <model_name>/
‚îÇ       ‚îú‚îÄ‚îÄ best.onnx
‚îÇ       ‚îú‚îÄ‚îÄ best_fp16.rknn
‚îÇ       ‚îú‚îÄ‚îÄ best_int8.rknn
‚îÇ       ‚îî‚îÄ‚îÄ model_config.yaml
‚îÇ
‚îú‚îÄ‚îÄ onnx_to_rknn_converter/      # ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏õ‡∏•‡∏á ONNX ‚Üí RKNN
‚îÇ   ‚îî‚îÄ‚îÄ universal_onnx_to_rknn.py
‚îÇ
‚îú‚îÄ‚îÄ requirement-step-summary/    # Templates ‡πÅ‡∏•‡∏∞ Config
‚îÇ   ‚îú‚îÄ‚îÄ 01_OVERVIEW.md           # Workflow overview
‚îÇ   ‚îú‚îÄ‚îÄ 02_FIELD_CATEGORIES.md   # ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å fields ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏î‡πâ/‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
‚îÇ   ‚îú‚îÄ‚îÄ templates/               # YAML templates
‚îÇ   ‚îî‚îÄ‚îÄ examples/                # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á (yolov8_bun)
‚îÇ
‚îî‚îÄ‚îÄ test/                        # Scripts ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    ‚îú‚îÄ‚îÄ file/                    # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    ‚îî‚îÄ‚îÄ tools/                   # ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö
```

---

## ‚ö° ‡∏Å‡∏é‡πÄ‡∏´‡∏•‡πá‡∏Å 4 ‡∏Ç‡πâ‡∏≠ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Custom Model

### 1Ô∏è‚É£ ‡∏ï‡πâ‡∏≠‡∏á "‡∏ï‡∏±‡∏î‡∏´‡∏±‡∏ß" (Remove Post-processing)

```
‚ùå ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏™‡πà‡πÉ‡∏ô Model:
   - NMS (Non-Maximum Suppression)
   - Decode Box (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏¥‡∏Å‡∏±‡∏î x, y, w, h)
   - Confidence Thresholding

‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:
   - ‡∏™‡πà‡∏á Feature Map (Raw Output) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
   - ‡∏ó‡∏≥ Post-processing ‡∏î‡πâ‡∏ß‡∏¢ Python/C++ ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Official SDK:**
```python
# NPU ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏Ñ‡πà Raw outputs
outputs = rknn.inference(inputs=[img])

# Post-process ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å NPU ‡∏î‡πâ‡∏ß‡∏¢ Python
boxes, classes, scores = yolov5_post_process(outputs)
```

### 2Ô∏è‚É£ ‡∏ï‡πâ‡∏≠‡∏á Static Shape (‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏á‡∏ó‡∏µ‡πà)

```python
# ‚ùå ‡∏ú‡∏¥‡∏î - Dynamic shape
torch.onnx.export(
    model, dummy_input, "model.onnx",
    dynamic_axes={'images': {0: 'batch', 2: 'height', 3: 'width'}}  # ‡∏´‡πâ‡∏≤‡∏°!
)

# ‚úÖ ‡∏ñ‡∏π‡∏Å - Static shape
torch.onnx.export(
    model, 
    torch.randn(1, 3, 640, 640),  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
    "model.onnx",
    opset_version=12
    # ‡πÑ‡∏°‡πà‡∏°‡∏µ dynamic_axes
)
```

**‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•:** NPU ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≠‡∏á Memory ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö Fixed size

### 3Ô∏è‚É£ ‡πÉ‡∏ä‡πâ ONNX Opset 12-19 (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 12)

```python
# ‚úÖ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ - Opset 12 (‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)
torch.onnx.export(model, dummy_input, "model.onnx", opset_version=12)

# ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ - Opset 13-19
torch.onnx.export(model, dummy_input, "model.onnx", opset_version=19)
```

### 4Ô∏è‚É£ ‡∏£‡∏∞‡∏ß‡∏±‡∏á 5D Tensor ‡πÅ‡∏•‡∏∞ Reshape/Transpose

```
‚ùå ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á:
   - Reshape ‡πÄ‡∏õ‡πá‡∏ô 5 ‡∏°‡∏¥‡∏ï‡∏¥‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
   - Permute ‡∏°‡∏¥‡∏ï‡∏¥‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

‚úÖ ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥:
   - ‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ NPU ‡∏™‡πà‡∏á output ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô
   - ‡∏ó‡∏≥ Reshape/Transpose ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ Python
```

---

## üìä Workflow ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á Model

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 1: Training (PyTorch)                                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Output: best.pt, training_source.yaml, performance_pt.json      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 2: Export (ONNX)                                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Output: best.onnx, onnx_source.yaml, performance_onnx.json      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Phase 3: Conversion (RKNN)                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Output: best_fp16.rknn, best_int8.rknn, rknn_source.yaml        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏õ‡∏•‡∏á FP16 (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)

```bash
python universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_fp16.rknn \
    --platform rk3588
```

### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏õ‡∏•‡∏á INT8 (Production)

```bash
python universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_int8.rknn \
    --platform rk3588 \
    --quantize \
    --algorithm mmse \
    --dataset dataset.txt
```

---

## üîí Critical Fields (‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô!)

‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ **‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô Training** ‡∏ó‡∏∏‡∏Å Phase:

| Field | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (YOLOv8) | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ |
|-------|-------------------|----------|
| `input_size` | `[640, 640]` | ‡∏Ç‡∏ô‡∏≤‡∏î Input ‡∏ó‡∏µ‡πà Model ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ |
| `input_format` | `"RGB"` | Color format (RGB/BGR) |
| `channels` | `3` | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô channels |
| `resize_method` | `"letterbox"` | ‡∏ß‡∏¥‡∏ò‡∏µ Resize (letterbox/direct) |
| `padding_color` | `[114, 114, 114]` | ‡∏™‡∏µ Padding (‡πÄ‡∏ó‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YOLO) |
| `normalize.mean` | `[0, 0, 0]` | Mean normalization |
| `normalize.std` | `[255, 255, 255]` | Std normalization |

### ‚ö†Ô∏è ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ:

```
‚ùå Model ‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
‚ùå Accuracy ‡∏•‡∏î‡∏•‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å (>20%)
‚ùå ‡∏ï‡πâ‡∏≠‡∏á Retrain Model ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
```

---

## ‚úÖ Configurable Fields (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏î‡πâ)

### Platform Settings

| Field | Options | Default | Notes |
|-------|---------|---------|-------|
| `platform` | rk3588, rk3576, rk3562, rv1109, rv1126, rk1808 | `rk3588` | ‡∏ï‡∏≤‡∏° hardware |

### Quantization Settings

| Field | Options | Default | Notes |
|-------|---------|---------|-------|
| `quantization.type` | FP16, INT8, UINT8 | `FP16` | FP16=accuracy, INT8=speed |
| `quantization.algorithm` | normal, mmse, kl_divergence | `normal` | mmse=accuracy ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ |
| `quantization.method` | channel, layer | `channel` | channel=accuracy ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ |
| `optimization_level` | 0, 1, 2, 3 | `3` | 3=optimized ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î |

### Inference Settings

| Field | Range | Default | Notes |
|-------|-------|---------|-------|
| `conf_threshold` | 0.0 - 1.0 | `0.25` | ‡∏™‡∏π‡∏á=detections ‡∏ô‡πâ‡∏≠‡∏¢ |
| `iou_threshold` | 0.0 - 1.0 | `0.85` | ‡∏™‡∏π‡∏á=NMS ‡∏Å‡∏£‡∏≠‡∏á‡∏ô‡πâ‡∏≠‡∏¢ |
| `max_detections` | 1 - 1000 | `300` | Maximum output boxes |

---

## üìù Preprocessing Pipeline (YOLOv8)

```python
def preprocess_image(image_path, target_size=640):
    """
    Preprocessing pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YOLOv8
    ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏ï‡∏≠‡∏ô Train Model ‡πÑ‡∏°‡πà‡∏á‡∏±‡πâ‡∏ô Model ‡∏à‡∏∞‡∏á‡∏á!
    """
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
    img = cv2.imread(image_path)  # Shape: (H, W, 3) - BGR
    h, w = img.shape[:2]
    
    # 2. Letterbox Resize (‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô)
    scale = min(target_size / h, target_size / w)
    new_h, new_w = int(h * scale), int(w * scale)
    img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    # 3. Padding ‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏µ‡πÄ‡∏ó‡∏≤ (114, 114, 114) - ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô YOLO
    img_padded = np.full((target_size, target_size, 3), 114, dtype=np.uint8)
    pad_h = (target_size - new_h) // 2
    pad_w = (target_size - new_w) // 2
    img_padded[pad_h:pad_h+new_h, pad_w:pad_w+new_w] = img_resized
    
    # 4. Color Conversion (BGR ‚Üí RGB)
    img_rgb = cv2.cvtColor(img_padded, cv2.COLOR_BGR2RGB)
    
    # 5. Add Batch Dimension
    img_array = np.expand_dims(img_rgb, axis=0)  # (640,640,3) ‚Üí (1,640,640,3)
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Postprocessing
    return img_array, (h, w), scale, (pad_w, pad_h)
```

### ‚ö†Ô∏è ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á

| ‚ùå ‡∏ú‡∏¥‡∏î | ‚úÖ ‡∏ñ‡∏π‡∏Å | ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏• |
|--------|---------|---------|
| Direct Resize | Letterbox + Padding | ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏π‡∏õ ‡πÑ‡∏°‡πà‡∏ö‡∏¥‡∏î |
| Padding ‡∏™‡∏µ‡∏î‡∏≥ (0,0,0) | Padding ‡∏™‡∏µ‡πÄ‡∏ó‡∏≤ (114,114,114) | ‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô YOLO Training |
| BGR Color Space | RGB Color Space | Model Train ‡∏î‡πâ‡∏ß‡∏¢ RGB |

---

## üìù Postprocessing Pipeline (YOLOv8)

```python
def postprocess_yolo(outputs, original_shape, scale, padding, 
                     conf_threshold=0.25, iou_threshold=0.85):
    """
    Postprocessing pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YOLOv8
    """
    
    # 1. Extract predictions
    predictions = outputs[0][0]  # (5, 8400) ‡∏´‡∏£‡∏∑‡∏≠ (8400, 5)
    
    # 2. Transpose ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    if predictions.shape[0] < predictions.shape[1]:
        predictions = predictions.T  # (5, 8400) ‚Üí (8400, 5)
    
    # 3. Decode predictions
    boxes = predictions[:, :4]        # x, y, w, h (center format)
    confidences = predictions[:, 4]   # confidence scores
    
    # 4. Filter by Confidence Threshold
    valid_mask = confidences > conf_threshold
    boxes = boxes[valid_mask]
    scores = confidences[valid_mask]
    
    # 5. Convert to Corner Format (x1, y1, x2, y2)
    boxes_xyxy = np.copy(boxes)
    boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2  # x1
    boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2  # y1
    boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2  # x2
    boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2  # y2
    
    # 6. Non-Maximum Suppression (NMS)
    indices = cv2.dnn.NMSBoxes(
        boxes_xyxy.tolist(),
        scores.tolist(),
        conf_threshold,
        iou_threshold  # ‚úÖ 0.85 = ‡∏Å‡∏£‡∏≠‡∏á‡∏ô‡πâ‡∏≠‡∏¢, 0.45 = ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏¢‡∏≠‡∏∞
    )
    
    # 7. Scale back to Original Coordinates
    if len(indices) > 0:
        indices = indices.flatten()
        boxes_xyxy = boxes_xyxy[indices]
        scores = scores[indices]
        
        # ‡∏•‡∏ö Padding
        pad_w, pad_h = padding
        boxes_xyxy[:, [0, 2]] -= pad_w
        boxes_xyxy[:, [1, 3]] -= pad_h
        
        # Scale ‡∏Å‡∏•‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á
        boxes_xyxy /= scale
        
        # Clip ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏£‡∏π‡∏õ
        h, w = original_shape
        boxes_xyxy[:, [0, 2]] = np.clip(boxes_xyxy[:, [0, 2]], 0, w)
        boxes_xyxy[:, [1, 3]] = np.clip(boxes_xyxy[:, [1, 3]], 0, h)
        
        return boxes_xyxy, scores
    
    return [], []
```

---

## ‚ö†Ô∏è ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ

### 1. üî¥ Detection Loss (ONNX ‡πÑ‡∏î‡πâ 23, RKNN ‡πÑ‡∏î‡πâ 6)

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
- Preprocessing ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á (Direct resize ‡πÅ‡∏ó‡∏ô Letterbox)
- IoU threshold ‡∏ï‡πà‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô (0.45 ‚Üí NMS ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏¢‡∏≠‡∏∞)
- Confidence threshold ‡∏™‡∏π‡∏á‡πÄ‡∏Å‡∏¥‡∏ô

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```python
# ‚úÖ ‡πÉ‡∏ä‡πâ Letterbox + Gray Padding
img_padded = np.full((640, 640, 3), 114, dtype=np.uint8)

# ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° IoU Threshold
iou_threshold = 0.85  # ‡∏à‡∏≤‡∏Å 0.45

# ‚úÖ ‡∏•‡∏î Confidence Threshold
conf_threshold = 0.25  # ‡∏à‡∏≤‡∏Å 0.5
```

### 2. üî¥ Accuracy ‡∏ï‡πà‡∏≥‡∏´‡∏•‡∏±‡∏á INT8 Quantization

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
- Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö calibration ‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô
- ‡πÉ‡∏ä‡πâ test set ‡πÉ‡∏ô dataset.txt (data leakage)
- Algorithm ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```bash
# ‚úÖ ‡πÉ‡∏ä‡πâ dataset 500-1000 ‡∏£‡∏π‡∏õ (‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢)
python create_dataset_txt.py -i ./train/images -d my_model -n 1000

# ‚úÖ ‡πÉ‡∏ä‡πâ algorithm = "mmse"
python universal_onnx_to_rknn.py --algorithm mmse ...

# ‚úÖ ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ test set ‡πÉ‡∏ô dataset.txt
```

### 3. üî¥ Coordinates ‡∏ú‡∏¥‡∏î‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
- ‡∏•‡∏∑‡∏°‡∏•‡∏ö Padding
- ‡∏•‡∏∑‡∏° Scale ‡∏Å‡∏•‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á
- ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏¥‡∏î

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```python
# ‚úÖ ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
boxes[:, [0, 2]] -= pad_w      # 1. ‡∏•‡∏ö Padding ‡∏Å‡πà‡∏≠‡∏ô
boxes[:, [1, 3]] -= pad_h
boxes /= scale                  # 2. Scale ‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á
```

### 4. üî¥ ONNX Export Error

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```python
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö opset version
# YOLOv8: opset_version=12
# YOLOv10: opset_version=13

torch.onnx.export(
    model, dummy_input, "model.onnx",
    opset_version=12,
    do_constant_folding=True
)
```

### 5. üî¥ Output Shape ‡∏ú‡∏¥‡∏î

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
- RKNN output (5, 8400) ‡πÅ‡∏ï‡πà‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á (8400, 5)

**‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**
```python
# ‚úÖ Auto-transpose
if predictions.shape[0] < predictions.shape[1]:
    predictions = predictions.T
```

---

## üìä Performance Benchmarks

### YOLOv8 Bun Detection (640x640, 1 class)

| Platform | Format | FPS | mAP@0.5 | Detection Rate |
|----------|--------|-----|---------|----------------|
| PyTorch | FP32 | 50 | 0.95 | 23/23 (100%) |
| ONNX | FP32 | 6.9 | 0.95 | 23/23 (100%) |
| RKNN | FP16 | 21.3 | 0.95 | 23/23 (100%) |
| RKNN | INT8 | 35.7 | 0.93 | 22/23 (95.7%) |

### Quantization Algorithm Comparison

| Algorithm | Speed | Accuracy | Use Case |
|-----------|-------|----------|----------|
| `normal` | ‚ö°‚ö°‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏∏‡∏î | ‚≠ê‚≠ê | Prototyping |
| `mmse` | ‚ö°‚ö° ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á | ‚≠ê‚≠ê‚≠ê | Production |
| `kl_divergence` | ‚ö° ‡∏ä‡πâ‡∏≤ | ‚≠ê‚≠ê‚≠ê | Special cases |

### FP16 vs INT8

| | FP16 | INT8 |
|---|------|------|
| **Accuracy** | ‚úÖ ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (99%) | ‚ö†Ô∏è ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (95-98%) |
| **Speed** | ‚ö° Baseline | ‚ö°‚ö°‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ 2-4x |
| **Size** | üì¶ Baseline | üì¶ ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50% |
| **Use case** | Development | Production |

---

## üöÄ ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢

### ‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset.txt (500-1000 ‡∏£‡∏π‡∏õ)
python create_dataset_txt.py -i ./images -d my_model -n 1000
```

### ‡πÅ‡∏õ‡∏•‡∏á ONNX ‚Üí RKNN

```bash
# FP16 (Development - Accuracy ‡∏™‡∏π‡∏á)
python universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_fp16.rknn \
    --platform rk3588

# INT8 (Production - Speed ‡∏™‡∏π‡∏á)
python universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_int8.rknn \
    --platform rk3588 \
    --quantize \
    --algorithm mmse \
    --dataset dataset.txt \
    --verify
```

### Export PyTorch ‚Üí ONNX

```python
import torch

model = torch.load("best.pt")
model.eval()

dummy_input = torch.randn(1, 3, 640, 640)
torch.onnx.export(
    model,
    dummy_input,
    "model.onnx",
    opset_version=12,
    input_names=['images'],
    output_names=['output0'],
    do_constant_folding=True
)
```

### ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ö‡∏ô RK3588

```bash
python Bun-detech.py --model model.rknn --image test.jpg
```

---

## üìñ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå

| ‡πÑ‡∏ü‡∏•‡πå | ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ |
|------|---------|
| `Doc/Custom_Model_to_RKNN_Guide_v2.3.2.md` | ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ Custom Model ‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå |
| `Doc/PREPROCESSING_POSTPROCESSING_GUIDE.md` | ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ Pre/Post processing |
| `Doc/UNIVERSAL_CONVERTER_GUIDE.md` | ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ Converter ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á |
| `requirement-step-summary/01_OVERVIEW.md` | Workflow overview |
| `requirement-step-summary/02_FIELD_CATEGORIES.md` | ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å fields ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏î‡πâ/‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ |

---

## üí° Quick Reference - ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°

| ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° | ‡∏ï‡∏≠‡∏ö/‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ |
|-------|-----------|
| ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á Model | ‡πÉ‡∏ä‡πâ `universal_onnx_to_rknn.py` |
| ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Dataset | ‡πÉ‡∏ä‡πâ `create_dataset_txt.py` (500-1000 ‡∏£‡∏π‡∏õ) |
| Preprocessing/Postprocessing | ‡∏î‡∏π `PREPROCESSING_POSTPROCESSING_GUIDE.md` |
| Custom Model | ‡∏î‡∏π `Custom_Model_to_RKNN_Guide_v2.3.2.md` |
| Config ‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô | ‡∏î‡∏π `02_FIELD_CATEGORIES.md` |
| Detection Loss | ‡πÄ‡∏û‡∏¥‡πà‡∏° `iou_threshold` ‡πÄ‡∏õ‡πá‡∏ô 0.85 |
| INT8 Accuracy ‡∏ï‡πà‡∏≥ | ‡πÉ‡∏ä‡πâ `--algorithm mmse` + dataset 1000 ‡∏£‡∏π‡∏õ |
| ONNX Operators ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö | Opset 12-19, ‡∏î‡∏π SDK documentation |

---

## üîó External Links

- [RKNN-Toolkit2 GitHub](https://github.com/rockchip-linux/rknn-toolkit2)
- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [ONNX Documentation](https://onnx.ai/onnx/)

---

**Hardware:** EC-R3588SPC (RK3588, 6 TOPS NPU)  
**Toolkit:** RKNN-Toolkit2 v2.3.2  
**Python:** 3.8+  
**Last Updated:** December 1, 2025
