# ğŸ“š à¸„à¸¹à¹ˆà¸¡à¸·à¸­ Preprocessing à¹à¸¥à¸° Postprocessing à¸ªà¸³à¸«à¸£à¸±à¸š RKNN Model

## ğŸ¯ Overview

à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡ AI Model à¹à¸šà¹ˆà¸‡à¸­à¸­à¸à¹€à¸›à¹‡à¸™ 3 à¸ªà¹ˆà¸§à¸™à¸«à¸¥à¸±à¸:

```
Input Image â†’ [Preprocessing] â†’ [Model/NPU] â†’ [Postprocessing] â†’ Final Results
   (à¸ˆà¸£à¸´à¸‡)         (à¹€à¸£à¸²à¹€à¸‚à¸µà¸¢à¸™)      (à¸„à¸³à¸™à¸§à¸“)        (à¹€à¸£à¸²à¹€à¸‚à¸µà¸¢à¸™)         (à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)
```

---

## ğŸ“Š Pipeline à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

### à¸ à¸²à¸à¸£à¸§à¸¡à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

| à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™ | Input | Output | à¸œà¸¹à¹‰à¸£à¸±à¸šà¸œà¸´à¸”à¸Šà¸­à¸š |
|---------|-------|--------|--------------|
| **Preprocessing** | à¸£à¸¹à¸›à¸ à¸²à¸à¸ˆà¸£à¸´à¸‡ (à¹€à¸Šà¹ˆà¸™ 1108x1477) | Tensor (1,640,640,3) | ğŸ‘¨â€ğŸ’» Developer |
| **Model Inference** | Tensor (1,640,640,3) | Raw Output (1,5,8400) | ğŸ¤– NPU/Model |
| **Postprocessing** | Raw Output (1,5,8400) | Bounding Boxes + Labels | ğŸ‘¨â€ğŸ’» Developer |

---

## 1ï¸âƒ£ Preprocessing (à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¹ˆà¸­à¸™à¹€à¸‚à¹‰à¸² Model)

### ğŸ¯ à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ
à¹à¸›à¸¥à¸‡à¸£à¸¹à¸›à¸ à¸²à¸à¸ˆà¸£à¸´à¸‡à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ **Input Format** à¸—à¸µà¹ˆ Model à¸„à¸²à¸”à¸«à¸§à¸±à¸‡

### ğŸ“ à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸ªà¸³à¸«à¸£à¸±à¸š YOLOv8

```python
def preprocess_image(image_path, target_size=640):
    """
    Preprocessing pipeline à¸ªà¸³à¸«à¸£à¸±à¸š YOLOv8
    à¸•à¹‰à¸­à¸‡à¸—à¸³à¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸šà¸•à¸­à¸™ Train Model à¹„à¸¡à¹ˆà¸‡à¸±à¹‰à¸™ Model à¸ˆà¸°à¸‡à¸‡!
    """
    
    # 1. à¹‚à¸«à¸¥à¸”à¸£à¸¹à¸›à¸ à¸²à¸
    img = cv2.imread(image_path)  # Shape: (H, W, 3) - BGR
    h, w = img.shape[:2]
    
    # 2. Letterbox Resize (à¸£à¸±à¸à¸©à¸²à¸­à¸±à¸•à¸£à¸²à¸ªà¹ˆà¸§à¸™)
    scale = min(target_size / h, target_size / w)
    new_h, new_w = int(h * scale), int(w * scale)
    img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    
    # 3. Padding à¸”à¹‰à¸§à¸¢à¸ªà¸µà¹€à¸—à¸² (114, 114, 114) - à¸¡à¸²à¸•à¸£à¸à¸²à¸™ YOLO
    img_padded = np.full((target_size, target_size, 3), 114, dtype=np.uint8)
    pad_h = (target_size - new_h) // 2
    pad_w = (target_size - new_w) // 2
    img_padded[pad_h:pad_h+new_h, pad_w:pad_w+new_w] = img_resized
    
    # 4. Color Conversion (BGR â†’ RGB)
    img_rgb = cv2.cvtColor(img_padded, cv2.COLOR_BGR2RGB)
    
    # 5. Add Batch Dimension
    img_array = np.expand_dims(img_rgb, axis=0)  # (640,640,3) â†’ (1,640,640,3)
    
    # à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸š Postprocessing
    return img_array, (h, w), scale, (pad_w, pad_h)
```

### âš ï¸ à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸°à¸§à¸±à¸‡

| âŒ à¸œà¸´à¸” | âœ… à¸–à¸¹à¸ | à¹€à¸«à¸•à¸¸à¸œà¸¥ |
|--------|---------|---------|
| Direct Resize `cv2.resize(img, (640,640))` | Letterbox + Padding | à¸£à¸±à¸à¸©à¸²à¸­à¸±à¸•à¸£à¸²à¸ªà¹ˆà¸§à¸™à¸£à¸¹à¸› à¹„à¸¡à¹ˆà¸šà¸´à¸” |
| Padding à¸ªà¸µà¸”à¸³ (0,0,0) | Padding à¸ªà¸µà¹€à¸—à¸² (114,114,114) | à¸•à¸²à¸¡à¸¡à¸²à¸•à¸£à¸à¸²à¸™ YOLO Training |
| BGR Color Space | RGB Color Space | Model Train à¸”à¹‰à¸§à¸¢ RGB |
| à¹„à¸¡à¹ˆ Normalize | Normalize (mean/std à¸«à¸£à¸·à¸­ Ã·255) | à¸‚à¸¶à¹‰à¸™à¸à¸±à¸š Model Config |

### ğŸ” à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¹à¸›à¸¥à¸‡

```
Input:  1108x1477 pixels (à¸ªà¸µà¸™à¹‰à¸³à¹€à¸‡à¸´à¸™-à¹€à¸«à¸¥à¸·à¸­à¸‡-à¹à¸”à¸‡)
         â†“
Step 1: Scale = min(640/1477, 640/1108) = 0.433
        â†’ Resize à¹€à¸›à¹‡à¸™ 480x640
         â†“
Step 2: Padding 80 pixels à¸‹à¹‰à¸²à¸¢-à¸‚à¸§à¸² (à¸ªà¸µà¹€à¸—à¸² 114)
        â†’ à¹„à¸”à¹‰ 640x640 pixels
         â†“
Step 3: BGR â†’ RGB
         â†“
Step 4: Add batch dimension
        â†’ Shape: (1, 640, 640, 3)
         â†“
Ready for Model! âœ…
```

---

## 2ï¸âƒ£ Model Inference (NPU à¸„à¸³à¸™à¸§à¸“)

### ğŸ¯ à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ
à¸£à¸±à¸š Input Tensor â†’ à¸„à¸³à¸™à¸§à¸“à¸”à¹‰à¸§à¸¢ Neural Network â†’ à¸ªà¹ˆà¸‡ Output Tensor

### ğŸ¤– à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸ à¸²à¸¢à¹ƒà¸™

```python
# Model à¹€à¸›à¹‡à¸™ Black Box à¸—à¸µà¹ˆà¸—à¸³à¸‡à¸²à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´
outputs = rknn.inference(inputs=[img_array])

# Input:  (1, 640, 640, 3)  â† à¸£à¸¹à¸›à¸—à¸µà¹ˆà¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹à¸¥à¹‰à¸§
# Output: (1, 5, 8400)       â† à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸”à¸´à¸š (Raw predictions)
```

### ğŸ“Š à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢à¸‚à¸­à¸‡ Output

```
Shape: (1, 5, 8400)
       â”‚  â”‚   â””â”€â”€â”€ 8400 predictions (grid cells)
       â”‚  â””â”€â”€â”€â”€â”€â”€â”€ 5 values per prediction:
       â”‚            [x, y, w, h, confidence]
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Batch size = 1
```

### ğŸ’¡ à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆ Model à¹„à¸¡à¹ˆà¸£à¸¹à¹‰

- âŒ à¸‚à¸™à¸²à¸”à¸£à¸¹à¸›à¸ à¸²à¸à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š (1108x1477)
- âŒ à¸¡à¸µ Padding à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ (80 pixels)
- âŒ Scale factor (0.433)
- âŒ Class name ("bun")
- âŒ à¸ˆà¸³à¸™à¸§à¸™ bbox à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£

**ğŸ‘‰ Model à¹à¸„à¹ˆà¸„à¸³à¸™à¸§à¸“à¸•à¸±à¸§à¹€à¸¥à¸‚à¸•à¸²à¸¡ Weight à¸—à¸µà¹ˆ Train à¹„à¸§à¹‰!**

---

## 3ï¸âƒ£ Postprocessing (à¹à¸›à¸¥à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹ƒà¸«à¹‰à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰)

### ğŸ¯ à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ
à¹à¸›à¸¥à¸‡ **Raw Output Tensor** à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ **Bounding Boxes** à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰à¸ˆà¸£à¸´à¸‡

### ğŸ“ à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸ªà¸³à¸«à¸£à¸±à¸š YOLOv8

```python
def postprocess_yolo(outputs, original_shape, scale, padding, 
                     conf_threshold=0.25, iou_threshold=0.85):
    """
    Postprocessing pipeline à¸ªà¸³à¸«à¸£à¸±à¸š YOLOv8
    """
    
    # 1. Extract predictions
    predictions = outputs[0][0]  # (5, 8400) à¸«à¸£à¸·à¸­ (8400, 5)
    
    # 2. Transpose à¸–à¹‰à¸²à¸ˆà¸³à¹€à¸›à¹‡à¸™
    if predictions.shape[0] < predictions.shape[1]:
        predictions = predictions.T  # (5, 8400) â†’ (8400, 5)
    
    # 3. Decode predictions
    boxes = predictions[:, :4]        # x, y, w, h (center format)
    confidences = predictions[:, 4]   # confidence scores
    
    # 4. Filter by Confidence Threshold
    valid_mask = confidences > conf_threshold
    boxes = boxes[valid_mask]
    scores = confidences[valid_mask]
    # à¸ˆà¸²à¸ 8400 predictions â†’ à¹€à¸«à¸¥à¸·à¸­ ~218 predictions
    
    # 5. Convert to Corner Format (x1, y1, x2, y2)
    boxes_xyxy = np.copy(boxes)
    boxes_xyxy[:, 0] = boxes[:, 0] - boxes[:, 2] / 2  # x1
    boxes_xyxy[:, 1] = boxes[:, 1] - boxes[:, 3] / 2  # y1
    boxes_xyxy[:, 2] = boxes[:, 0] + boxes[:, 2] / 2  # x2
    boxes_xyxy[:, 3] = boxes[:, 1] + boxes[:, 3] / 2  # y2
    
    # 6. Non-Maximum Suppression (NMS)
    indices = cv2.dnn.NMSBoxes(
        boxes_xyxy.tolist(),
        scores.tolist(),
        conf_threshold,
        iou_threshold  # âœ… 0.85 = à¸à¸£à¸­à¸‡à¸™à¹‰à¸­à¸¢, 0.45 = à¸à¸£à¸­à¸‡à¹€à¸¢à¸­à¸°
    )
    # à¸ˆà¸²à¸ 218 boxes â†’ à¹€à¸«à¸¥à¸·à¸­ 23 boxes (bbox à¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”)
    
    # 7. Scale back to Original Coordinates
    if len(indices) > 0:
        indices = indices.flatten()
        boxes_xyxy = boxes_xyxy[indices]
        scores = scores[indices]
        
        # à¸¥à¸š Padding
        pad_w, pad_h = padding
        boxes_xyxy[:, [0, 2]] -= pad_w  # Remove horizontal padding
        boxes_xyxy[:, [1, 3]] -= pad_h  # Remove vertical padding
        
        # Scale à¸à¸¥à¸±à¸šà¸‚à¸™à¸²à¸”à¸ˆà¸£à¸´à¸‡
        boxes_xyxy /= scale
        
        # Clip à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸‚à¸­à¸šà¹€à¸‚à¸•à¸£à¸¹à¸›
        h, w = original_shape
        boxes_xyxy[:, [0, 2]] = np.clip(boxes_xyxy[:, [0, 2]], 0, w)
        boxes_xyxy[:, [1, 3]] = np.clip(boxes_xyxy[:, [1, 3]], 0, h)
        
        return boxes_xyxy, scores
    
    return [], []
```

### ğŸ” à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”

#### **Step 1-2: Reshape Output**
```
(1, 5, 8400) â†’ (5, 8400) â†’ (8400, 5)
                Remove      Transpose
                batch dim   if needed
```

#### **Step 3: Decode Predictions**
```
(8400, 5) à¹à¸•à¹ˆà¸¥à¸°à¹à¸–à¸§:
[x_center, y_center, width, height, confidence]
[320.5,    240.3,    150.2, 180.7,  0.978     ]
```

#### **Step 4: Filter by Confidence**
```
Before: 8400 predictions
Filter: confidence > 0.25
After:  218 predictions âœ…
```

#### **Step 5: Convert Format**
```
Center Format (x, y, w, h):
[320, 240, 150, 180]

Corner Format (x1, y1, x2, y2):
[245, 150, 395, 330]
     â†‘    â†‘    â†‘    â†‘
    x1   y1   x2   y2
```

#### **Step 6: Non-Maximum Suppression**
```
Input: 218 overlapping boxes

NMS with IoU = 0.85:
- à¸–à¹‰à¸² 2 boxes à¸‹à¹‰à¸­à¸™à¸à¸±à¸™ > 85% â†’ à¹€à¸­à¸²à¹à¸„à¹ˆà¸­à¸±à¸™à¸—à¸µà¹ˆ confidence à¸ªà¸¹à¸‡à¸à¸§à¹ˆà¸²
- à¸–à¹‰à¸² 2 boxes à¸‹à¹‰à¸­à¸™à¸à¸±à¸™ < 85% â†’ à¹€à¸à¹‡à¸šà¸—à¸±à¹‰à¸‡ 2 à¸­à¸±à¸™

Output: 23 best boxes âœ…
```

#### **Step 7: Coordinate Transformation**
```
Model Coordinates (640x640):
[x=320, y=240, w=150, h=180]
    â†“ à¸¥à¸š padding (80, 0)
[x=240, y=240, w=150, h=180]
    â†“ à¸«à¸²à¸£ scale (0.433)
[x=554, y=554, w=346, h=415]
    â†“ Clip to image (0-1108, 0-1477)
Original Coordinates (1108x1477) âœ…
```

---

## ğŸ¯ à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

### Input
```
à¸£à¸¹à¸›à¸ à¸²à¸: bun.jpg (1108x1477 pixels)
Model: best_yolov8_fp16.rknn
Classes: ["bun"]
```

### Preprocessing
```python
img_array, original_shape, scale, padding = preprocess_image("bun.jpg")

# à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ:
# - img_array: (1, 640, 640, 3) - Ready for Model
# - original_shape: (1477, 1108)
# - scale: 0.433
# - padding: (80, 0)
```

### Model Inference
```python
outputs = rknn.inference(inputs=[img_array])

# à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ:
# - outputs: [(1, 5, 8400)] - Raw predictions
# - Inference time: 46.97 ms
# - Throughput: 21.3 FPS
```

### Postprocessing
```python
boxes, scores = postprocess_yolo(
    outputs, 
    original_shape, 
    scale, 
    padding,
    conf_threshold=0.25,
    iou_threshold=0.85
)

# à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ:
# - boxes: 23 bounding boxes
# - scores: [0.978, 0.974, 0.970, ..., 0.900]
# - Detections: 23/23 âœ… (100% recovery)
```

---

## ğŸ“Š à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š Pre/Post Processing

| à¹à¸‡à¹ˆà¸¡à¸¸à¸¡ | Preprocessing | Postprocessing |
|--------|---------------|----------------|
| **Input** | à¸£à¸¹à¸›à¸ à¸²à¸à¸ˆà¸£à¸´à¸‡ (à¸‚à¸™à¸²à¸”à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¸™à¸­à¸™) | Raw tensor (à¸‚à¸™à¸²à¸”à¸„à¸‡à¸—à¸µà¹ˆ) |
| **Output** | Tensor à¸‚à¸™à¸²à¸”à¸„à¸‡à¸—à¸µà¹ˆ | Bounding boxes à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹„à¸”à¹‰ |
| **à¸à¸²à¸£à¹à¸›à¸¥à¸‡** | à¸£à¸¹à¸› â†’ Tensor | Tensor â†’ Boxes |
| **à¸•à¹‰à¸­à¸‡à¸£à¸¹à¹‰** | Input size Model à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ | Output format à¸‚à¸­à¸‡ Model |
| **à¸•à¹‰à¸­à¸‡à¹€à¸à¹‡à¸š** | Scale, Padding | - |
| **à¸„à¸§à¸²à¸¡à¸¢à¸²à¸** | â­â­ à¸•à¹‰à¸­à¸‡à¸£à¸°à¸§à¸±à¸‡à¸šà¸´à¸”à¸£à¸¹à¸› | â­â­â­â­ Logic à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™ |

---

## âš™ï¸ Parameters à¸ªà¸³à¸„à¸±à¸

### Preprocessing Parameters

| Parameter | à¸„à¹ˆà¸²à¹à¸™à¸°à¸™à¸³ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|-----------|----------|----------|
| `target_size` | 640 | à¸‚à¸™à¸²à¸” Input à¸—à¸µà¹ˆ Model à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ |
| `padding_color` | (114, 114, 114) | à¸ªà¸µà¹€à¸—à¸² - à¸¡à¸²à¸•à¸£à¸à¸²à¸™ YOLO |
| `interpolation` | INTER_LINEAR | à¸§à¸´à¸˜à¸µ Resize à¸£à¸¹à¸› |
| `color_format` | RGB | Format à¸—à¸µà¹ˆ Model Train |

### Postprocessing Parameters

| Parameter | à¸„à¹ˆà¸²à¹à¸™à¸°à¸™à¸³ | à¸œà¸¥à¸à¸£à¸°à¸—à¸š |
|-----------|----------|----------|
| `conf_threshold` | 0.25 | à¸•à¹ˆà¸³ = bbox à¹€à¸¢à¸­à¸°, à¸ªà¸¹à¸‡ = bbox à¸™à¹‰à¸­à¸¢ |
| `iou_threshold` | 0.85 | à¸ªà¸¹à¸‡ = à¸à¸£à¸­à¸‡ NMS à¸™à¹‰à¸­à¸¢, à¸•à¹ˆà¸³ = à¸à¸£à¸­à¸‡à¹€à¸¢à¸­à¸° |

### ğŸ” à¸œà¸¥à¸à¸£à¸°à¸—à¸šà¸‚à¸­à¸‡ IoU Threshold

```
IoU = 0.45 (à¹€à¸‚à¹‰à¸¡à¸‡à¸§à¸”):
218 boxes â†’ NMS â†’ 15 boxes âŒ (à¸à¸£à¸­à¸‡à¹€à¸¢à¸­à¸°à¹„à¸›)

IoU = 0.85 (à¸œà¹ˆà¸­à¸™à¸›à¸£à¸™):
218 boxes â†’ NMS â†’ 23 boxes âœ… (à¹„à¸”à¹‰à¸„à¸£à¸š!)
```

---

## ğŸš¨ à¸›à¸±à¸à¸«à¸²à¸—à¸µà¹ˆà¸à¸šà¸šà¹ˆà¸­à¸¢

### 1. Bbox Detection Loss

**à¸­à¸²à¸à¸²à¸£:** ONNX detect à¹„à¸”à¹‰ 23 bbox à¹à¸•à¹ˆ RKNN detect à¹„à¸”à¹‰à¹à¸„à¹ˆ 6 bbox

**à¸ªà¸²à¹€à¸«à¸•à¸¸:**
- âŒ Preprocessing à¹„à¸¡à¹ˆà¸•à¸£à¸‡ (Direct resize à¹à¸—à¸™ Letterbox)
- âŒ IoU threshold à¸•à¹ˆà¸³à¹€à¸à¸´à¸™ (0.45 â†’ NMS à¸à¸£à¸­à¸‡à¹€à¸¢à¸­à¸°)
- âŒ Confidence threshold à¸ªà¸¹à¸‡à¹€à¸à¸´à¸™

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
```python
# âœ… à¹ƒà¸Šà¹‰ Letterbox + Gray Padding
img_padded = np.full((640, 640, 3), 114, dtype=np.uint8)

# âœ… à¹€à¸à¸´à¹ˆà¸¡ IoU Threshold
iou_threshold = 0.85  # à¸ˆà¸²à¸ 0.45

# âœ… à¸¥à¸” Confidence Threshold
conf_threshold = 0.25  # à¸ˆà¸²à¸ 0.5
```

### 2. Coordinates à¹„à¸¡à¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¸£à¸¹à¸›à¸ˆà¸£à¸´à¸‡

**à¸­à¸²à¸à¸²à¸£:** Bbox à¸§à¸²à¸”à¸œà¸´à¸”à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡

**à¸ªà¸²à¹€à¸«à¸•à¸¸:**
- âŒ à¸¥à¸·à¸¡à¸¥à¸š Padding
- âŒ à¸¥à¸·à¸¡ Scale à¸à¸¥à¸±à¸šà¸‚à¸™à¸²à¸”à¸ˆà¸£à¸´à¸‡
- âŒ à¹ƒà¸Šà¹‰ Scale factor à¸œà¸´à¸”

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
```python
# âœ… à¸¥à¸³à¸”à¸±à¸šà¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
boxes[:, [0, 2]] -= pad_w      # 1. à¸¥à¸š Padding à¸à¹ˆà¸­à¸™
boxes[:, [1, 3]] -= pad_h
boxes /= scale                  # 2. Scale à¸à¸¥à¸±à¸šà¸—à¸µà¸«à¸¥à¸±à¸‡
```

### 3. Output Shape à¸œà¸´à¸”

**à¸­à¸²à¸à¸²à¸£:** Error shape mismatch

**à¸ªà¸²à¹€à¸«à¸•à¸¸:**
- âŒ RKNN output (5, 8400) à¹à¸•à¹ˆà¹‚à¸„à¹‰à¸”à¸„à¸²à¸”à¸«à¸§à¸±à¸‡ (8400, 5)

**à¸§à¸´à¸˜à¸µà¹à¸à¹‰:**
```python
# âœ… Auto-transpose
if predictions.shape[0] < predictions.shape[1]:
    predictions = predictions.T
```

---

## âœ… Checklist à¸à¸²à¸£ Debug

### Preprocessing
- [ ] à¸£à¸¹à¸›à¸•à¹‰à¸™à¸‰à¸šà¸±à¸šà¹‚à¸«à¸¥à¸”à¹„à¸”à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
- [ ] Letterbox resize (à¹„à¸¡à¹ˆà¸šà¸´à¸”à¸£à¸¹à¸›)
- [ ] Padding à¸ªà¸µà¹€à¸—à¸² (114, 114, 114)
- [ ] Color conversion BGR â†’ RGB
- [ ] Shape = (1, 640, 640, 3)
- [ ] à¸šà¸±à¸™à¸—à¸¶à¸ scale à¹à¸¥à¸° padding

### Model Inference
- [ ] Model à¹‚à¸«à¸¥à¸”à¸ªà¸³à¹€à¸£à¹‡à¸ˆ
- [ ] Runtime initialize à¹„à¸”à¹‰
- [ ] Output shape à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (1, 5, 8400)
- [ ] Inference time à¸ªà¸¡à¹€à¸«à¸•à¸¸à¸ªà¸¡à¸œà¸¥ (<100ms)

### Postprocessing
- [ ] Transpose shape à¸–à¹‰à¸²à¸ˆà¸³à¹€à¸›à¹‡à¸™
- [ ] Confidence threshold à¸•à¸£à¸‡à¸à¸±à¸š Training
- [ ] IoU threshold à¸ªà¸¹à¸‡à¸à¸­ (0.85)
- [ ] NMS à¸—à¸³à¸‡à¸²à¸™ (boxes à¸¥à¸”à¸¥à¸‡)
- [ ] à¸¥à¸š Padding à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
- [ ] Scale coordinates à¸à¸¥à¸±à¸š
- [ ] Clip à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸£à¸¹à¸›

---

## ğŸ“š à¸ªà¸£à¸¸à¸›

### ğŸ¯ à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸ªà¸³à¸„à¸±à¸

1. **Model = à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸„à¸³à¸™à¸§à¸“**
   - Input: Tensor â†’ Output: Tensor
   - à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢ à¹„à¸¡à¹ˆà¸£à¸¹à¹‰ Class à¹„à¸¡à¹ˆà¸£à¸¹à¹‰à¸‚à¸™à¸²à¸”à¸£à¸¹à¸›à¸ˆà¸£à¸´à¸‡

2. **Pre/Post Processing = à¸‡à¸²à¸™à¸‚à¸­à¸‡ Developer**
   - à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ + à¹à¸›à¸¥à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ
   - à¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™à¹€à¸­à¸‡à¹ƒà¸«à¹‰à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡

3. **à¸•à¹‰à¸­à¸‡à¸•à¸£à¸‡à¸à¸±à¸š Training**
   - Preprocessing à¸œà¸´à¸” â†’ Model à¸‡à¸‡ â†’ à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹à¸¢à¹ˆ
   - Postprocessing à¸œà¸´à¸” â†’ Coordinates à¸œà¸´à¸” â†’ Bbox à¸§à¸²à¸”à¸œà¸´à¸”à¸—à¸µà¹ˆ

### ğŸš€ Best Practices

```python
# âœ… DO
- à¹ƒà¸Šà¹‰ Letterbox resize (à¸£à¸±à¸à¸©à¸²à¸­à¸±à¸•à¸£à¸²à¸ªà¹ˆà¸§à¸™)
- Padding à¸ªà¸µà¹€à¸—à¸² (114, 114, 114)
- Convert BGR â†’ RGB
- IoU threshold à¸ªà¸¹à¸‡ (0.85)
- Confidence threshold à¸•à¸£à¸‡à¸à¸±à¸š Training (0.25)

# âŒ DON'T
- Direct resize (à¸šà¸´à¸”à¸£à¸¹à¸›)
- Padding à¸ªà¸µà¸”à¸³ (0, 0, 0)
- à¸¥à¸·à¸¡ Convert color space
- IoU threshold à¸•à¹ˆà¸³à¹€à¸à¸´à¸™ (0.45)
- Confidence threshold à¸ªà¸¹à¸‡à¹€à¸à¸´à¸™ (0.5)
```

### ğŸ“Š Performance Target

```
Preprocessing:  < 10 ms
Inference:      ~ 47 ms  (21.3 FPS)
Postprocessing: < 5 ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:          ~ 62 ms  (16 FPS)
```

### ğŸ‰ Success Criteria

- âœ… RKNN detections = ONNX detections (23/23 = 100%)
- âœ… Confidence scores à¸ªà¸¡à¹€à¸«à¸•à¸¸à¸ªà¸¡à¸œà¸¥ (0.9+)
- âœ… Coordinates à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (à¸§à¸²à¸” bbox à¸•à¸£à¸‡à¸‚à¸­à¸‡à¸ˆà¸£à¸´à¸‡)
- âœ… Performance à¸”à¸µ (> 20 FPS)

---

## ğŸ”— à¹€à¸­à¸à¸ªà¸²à¸£à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡

- [RKNN Toolkit2 Documentation](https://github.com/rockchip-linux/rknn-toolkit2)
- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [OpenCV Documentation](https://docs.opencv.org/)

---

**ğŸ“… Updated:** November 27, 2025  
**ğŸ“ Author:** Firefly EC-R3588SPC Development Team  
**ğŸ”– Version:** 1.0
