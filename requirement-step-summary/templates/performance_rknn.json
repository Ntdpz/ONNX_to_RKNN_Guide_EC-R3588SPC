{
  "report_info": {
    "model_name": "model_name",
    "model_version": "1.0.0",
    "model_type": "YOLOv8",
    "task": "object_detection",
    "test_date": "2025-11-27",
    "device": "NPU",
    "platform": "rk3588"
  },
  
  "test_configuration": {
    "test_image": "test.jpg",
    "image_size": [1920, 1080],
    "batch_size": 1,
    "hardware": "EC-R3588SPC",
    "npu_version": "3.0",
    "npu_tops": 6
  },
  
  "models_tested": {
    "fp16": {
      "file": "best_fp16.rknn",
      "quantization": "FP16",
      "tested": true
    },
    "int8": {
      "file": "best_int8.rknn",
      "quantization": "INT8",
      "tested": false
    }
  },
  
  "fp16_performance": {
    "accuracy_metrics": {
      "object_detection": {
        "mAP50": null,
        "mAP50_95": null,
        "precision": null,
        "recall": null,
        "f1_score": null
      }
    },
    
    "inference_performance": {
      "device": "NPU",
      "preprocessing_ms": null,
      "inference_ms": null,
      "postprocessing_ms": null,
      "total_ms": null,
      "fps": null
    },
    
    "test_results": {
      "detections": null,
      "confidence_range": [null, null],
      "boxes": null
    },
    
    "model_info": {
      "size_mb": null,
      "compression_ratio": null
    },
    
    "comparison_with_onnx": {
      "accuracy_drop_percent": null,
      "detections_match_percent": null,
      "confidence_drop": null,
      "speedup": null,
      "notes": [
        "FP16 should match ONNX 95-100%",
        "Speedup should be 2-4x on NPU",
        "Confidence drop should be < 0.03"
      ]
    }
  },
  
  "int8_performance": {
    "accuracy_metrics": {
      "object_detection": {
        "mAP50": null,
        "mAP50_95": null,
        "precision": null,
        "recall": null,
        "f1_score": null
      }
    },
    
    "inference_performance": {
      "device": "NPU",
      "preprocessing_ms": null,
      "inference_ms": null,
      "postprocessing_ms": null,
      "total_ms": null,
      "fps": null
    },
    
    "test_results": {
      "detections": null,
      "confidence_range": [null, null],
      "boxes": null
    },
    
    "model_info": {
      "size_mb": null,
      "compression_ratio": null,
      "dataset_size": 1000,
      "quantization_algorithm": "mmse"
    },
    
    "comparison_with_onnx": {
      "accuracy_drop_percent": null,
      "detections_match_percent": null,
      "confidence_drop": null,
      "speedup": null,
      "notes": [
        "INT8 should match ONNX 90-98%",
        "Speedup should be 4-8x on NPU",
        "Confidence drop should be < 0.08"
      ]
    }
  },
  
  "tuning_history": {
    "threshold_tuning": {
      "conf_threshold": {
        "tested_values": [],
        "optimal_value": 0.25,
        "notes": "Match training threshold"
      },
      "iou_threshold": {
        "tested_values": [],
        "optimal_value": 0.7,
        "notes": "Tune based on bbox recovery"
      }
    },
    "quantization_tuning": {
      "algorithm_tested": [],
      "optimal_algorithm": "mmse",
      "notes": ""
    }
  },
  
  "validation": {
    "fp16": {
      "passed": null,
      "issues": [],
      "recommendation": null
    },
    "int8": {
      "passed": null,
      "issues": [],
      "recommendation": null
    }
  },
  
  "deployment_recommendation": {
    "use_case": {
      "accuracy_priority": "FP16",
      "speed_priority": "INT8",
      "balanced": "FP16"
    },
    "notes": [
      "FP16 recommended for development and high-accuracy requirements",
      "INT8 recommended for production and real-time applications",
      "Test both on actual hardware before deployment"
    ]
  }
}
