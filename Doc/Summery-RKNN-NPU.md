# ðŸ“‹ RKNN NPU Complete Guide - EC-R3588SPC
**à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ NPU à¸šà¸™ RK3588 SoC**

---

## ðŸŽ¯ Overview
à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ NPU à¸šà¸™ EC-R3588SPC à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ **RKNN format** à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹‚à¸”à¸¢à¸•à¹‰à¸­à¸‡à¸œà¹ˆà¸²à¸™ **RKNN Server** à¹€à¸žà¸·à¹ˆà¸­à¹€à¸‚à¹‰à¸²à¸–à¸¶à¸‡ Hardware NPU

### ðŸ—ï¸ NPU Architecture
```
YOLOv5 Model (.pt/.onnx) â†’ RKNN Converter â†’ .rknn Model â†’ RKNN Server â†’ NPU Hardware
```

---

## ðŸ”„ à¸§à¸´à¸˜à¸µà¹à¸›à¸¥à¸‡ ONNX YOLOv5 FP32 à¹€à¸›à¹‡à¸™ RKNN

### ðŸ“‹ Requirements
```bash
- RKNN Toolkit2 v2.3.0+
- Python 3.8+
- ONNX Model (YOLOv5 format)
- Calibration Images (à¸ªà¸³à¸«à¸£à¸±à¸š INT8 quantization)
```

### ðŸ› ï¸ Step 1: à¹€à¸•à¸£à¸µà¸¢à¸¡ Environment
```bash
# Install RKNN Toolkit2
pip install rknn-toolkit2

# Verify installation
python3 -c "from rknn import RKNN; print('RKNN OK')"
```

### ðŸ”§ Step 2: à¹à¸›à¸¥à¸‡ ONNX à¹€à¸›à¹‡à¸™ RKNN
```python
#!/usr/bin/env python3
# onnx_to_rknn_converter.py

from rknn import RKNN
import numpy as np
import cv2
import os

def convert_yolov5_to_rknn(onnx_path, rknn_path, quantize=True):
    """
    à¹à¸›à¸¥à¸‡ YOLOv5 ONNX à¹€à¸›à¹‡à¸™ RKNN format
    
    Args:
        onnx_path: path à¹„à¸Ÿà¸¥à¹Œ ONNX
        rknn_path: path output RKNN
        quantize: à¹ƒà¸Šà¹‰ INT8 quantization à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    """
    
    # 1. à¸ªà¸£à¹‰à¸²à¸‡ RKNN object
    rknn = RKNN(verbose=True)
    
    try:
        # 2. Config à¸ªà¸³à¸«à¸£à¸±à¸š RK3588
        print("ðŸ”§ Configuring for RK3588...")
        ret = rknn.config(
            mean_values=[[0, 0, 0]],           # YOLOv5 normalization
            std_values=[[255, 255, 255]],      # Scale to 0-1
            target_platform='rk3588'           # Target hardware
        )
        if ret != 0:
            raise Exception("Config failed!")
        
        # 3. Load ONNX model
        print(f"ðŸ“¥ Loading ONNX: {onnx_path}")
        ret = rknn.load_onnx(model=onnx_path)
        if ret != 0:
            raise Exception("Load ONNX failed!")
        
        # 4. Build RKNN model
        print("ðŸ—ï¸ Building RKNN model...")
        if quantize:
            # à¸ªà¸³à¸«à¸£à¸±à¸š INT8 quantization (à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆ, à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸²)
            dataset_path = create_calibration_dataset()
            ret = rknn.build(do_quantization=True, dataset=dataset_path)
        else:
            # à¸ªà¸³à¸«à¸£à¸±à¸š FP32 (à¹à¸¡à¹ˆà¸™à¸¢à¸³à¸à¸§à¹ˆà¸²)
            ret = rknn.build(do_quantization=False)
        
        if ret != 0:
            raise Exception("Build failed!")
        
        # 5. Export RKNN file
        print(f"ðŸ’¾ Exporting to: {rknn_path}")
        ret = rknn.export_rknn(rknn_path)
        if ret != 0:
            raise Exception("Export failed!")
        
        print("âœ… Conversion completed successfully!")
        return True
        
    except Exception as e:
        print(f"ðŸ’¥ Error: {e}")
        return False
    
    finally:
        rknn.release()

def create_calibration_dataset(image_folder="./calibration_images", 
                              dataset_path="./dataset.txt"):
    """
    à¸ªà¸£à¹‰à¸²à¸‡ calibration dataset à¸ªà¸³à¸«à¸£à¸±à¸š INT8 quantization
    """
    if not os.path.exists(image_folder):
        print(f"âš ï¸ Creating sample calibration images...")
        os.makedirs(image_folder, exist_ok=True)
        
        # à¸ªà¸£à¹‰à¸²à¸‡à¸£à¸¹à¸›à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ (à¸„à¸§à¸£à¹ƒà¸Šà¹‰à¸£à¸¹à¸›à¸ˆà¸£à¸´à¸‡à¸ˆà¸²à¸ training set)
        for i in range(10):
            sample_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            cv2.imwrite(f"{image_folder}/sample_{i}.jpg", sample_img)
    
    # à¸ªà¸£à¹‰à¸²à¸‡ dataset.txt
    with open(dataset_path, 'w') as f:
        for img_file in os.listdir(image_folder):
            if img_file.endswith(('.jpg', '.png', '.jpeg')):
                f.write(f"{image_folder}/{img_file}\n")
    
    return dataset_path

# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™
if __name__ == "__main__":
    # Configuration
    ONNX_MODEL = "yolov5s.onnx"          # Input ONNX file
    RKNN_MODEL = "yolov5s_fp32.rknn"     # Output RKNN file
    
    # Convert with FP32 precision
    success = convert_yolov5_to_rknn(
        onnx_path=ONNX_MODEL,
        rknn_path=RKNN_MODEL,
        quantize=False  # FP32 mode
    )
    
    if success:
        print(f"ðŸŽ‰ Model converted: {RKNN_MODEL}")
        print(f"ðŸ“Š File size: {os.path.getsize(RKNN_MODEL)/1024/1024:.1f} MB")
    else:
        print("ðŸ’¥ Conversion failed!")
```

### ðŸš€ Step 3: à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Script
```bash
# à¹à¸›à¸¥à¸‡à¹‚à¸”à¸¢à¸•à¸£à¸‡
python3 onnx_to_rknn_converter.py

# à¸«à¸£à¸·à¸­à¹ƒà¸Šà¹‰à¸œà¹ˆà¸²à¸™ function
python3 -c "
from onnx_to_rknn_converter import convert_yolov5_to_rknn
convert_yolov5_to_rknn('model.onnx', 'model.rknn', quantize=False)
"
```

---

## ðŸŽ¯ à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ RKNN Model

### ðŸ“‹ Requirements
```bash
- RKNN Runtime (à¸¡à¸µà¹à¸¥à¹‰à¸§à¹ƒà¸™ EC-R3588SPC)
- RKNN Server (à¸£à¸±à¸™à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´)
- Python 3.8+ with rknn-toolkit2
```

### ðŸ”§ RKNN Inference Script
```python
#!/usr/bin/env python3
# npu_inference.py

import cv2
import numpy as np
from rknn import RKNN
import time

class NPUInference:
    def __init__(self, model_path, class_names=None):
        """
        Initialize NPU inference
        
        Args:
            model_path: path to .rknn model
            class_names: list of class names for detection
        """
        self.model_path = model_path
        self.class_names = class_names or []
        self.rknn = RKNN()
        self.input_size = 640  # YOLOv5 default
        
        # Load model
        self.load_model()
    
    def load_model(self):
        """Load RKNN model to NPU"""
        try:
            print(f"ðŸ“¥ Loading model: {self.model_path}")
            
            # Load RKNN model
            ret = self.rknn.load_rknn(self.model_path)
            if ret != 0:
                raise Exception("Failed to load RKNN model")
            
            # Initialize runtime (à¹ƒà¸Šà¹‰ NPU)
            ret = self.rknn.init_runtime()
            if ret != 0:
                raise Exception("Failed to initialize NPU runtime")
            
            print("âœ… NPU model loaded successfully")
            
        except Exception as e:
            print(f"ðŸ’¥ Error loading model: {e}")
            raise e
    
    def preprocess_image(self, image_path):
        """
        Preprocess image for YOLOv5 inference
        
        Args:
            image_path: path to input image
            
        Returns:
            processed_image, original_image, scale_factor, padding
        """
        # Read image
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Cannot read image: {image_path}")
        
        original_img = img.copy()
        h, w = img.shape[:2]
        
        # Calculate scale and padding for letterbox
        scale = min(self.input_size/w, self.input_size/h)
        new_w, new_h = int(w * scale), int(h * scale)
        
        # Resize image
        img_resized = cv2.resize(img, (new_w, new_h))
        
        # Create letterbox (pad to square)
        pad_w = (self.input_size - new_w) // 2
        pad_h = (self.input_size - new_h) // 2
        
        img_padded = cv2.copyMakeBorder(
            img_resized, pad_h, self.input_size-new_h-pad_h, 
            pad_w, self.input_size-new_w-pad_w, 
            cv2.BORDER_CONSTANT, value=(114, 114, 114)
        )
        
        # Convert to RGB and normalize
        img_rgb = cv2.cvtColor(img_padded, cv2.COLOR_BGR2RGB)
        
        # Add batch dimension
        img_input = np.expand_dims(img_rgb, axis=0)
        
        return img_input, original_img, scale, (pad_w, pad_h)
    
    def inference(self, image_path):
        """
        Run inference on NPU
        
        Args:
            image_path: path to input image
            
        Returns:
            detection results, inference time
        """
        try:
            # Preprocess
            img_input, original_img, scale, padding = self.preprocess_image(image_path)
            
            # Run inference
            print("âš¡ Running inference on NPU...")
            start_time = time.time()
            
            outputs = self.rknn.inference(inputs=[img_input])
            
            inference_time = (time.time() - start_time) * 1000  # ms
            
            print(f"âœ… Inference completed in {inference_time:.2f} ms")
            print(f"ðŸŽ¯ Throughput: {1000/inference_time:.1f} FPS")
            
            # Post-process results
            results = self.postprocess_yolo(outputs[0], original_img.shape, scale, padding)
            
            return results, inference_time
            
        except Exception as e:
            print(f"ðŸ’¥ Inference error: {e}")
            return None, 0
    
    def postprocess_yolo(self, output, img_shape, scale, padding):
        """
        Post-process YOLOv5 output
        
        Args:
            output: raw model output
            img_shape: original image shape (h, w, c)
            scale: scale factor from preprocessing
            padding: padding values (pad_w, pad_h)
            
        Returns:
            list of detections [x1, y1, x2, y2, confidence, class_id]
        """
        pad_w, pad_h = padding
        h, w = img_shape[:2]
        
        # Reshape output (batch, num_anchors, 5+num_classes)
        if len(output.shape) == 3:
            output = output[0]  # Remove batch dimension
        
        # Filter by confidence threshold
        conf_threshold = 0.5
        mask = output[:, 4] > conf_threshold
        output = output[mask]
        
        if len(output) == 0:
            return []
        
        # Extract box coordinates and class scores
        boxes = output[:, :4]
        scores = output[:, 4]
        class_scores = output[:, 5:] if output.shape[1] > 5 else np.ones((len(output), 1))
        
        # Get class predictions
        class_ids = np.argmax(class_scores, axis=1)
        confidences = scores * np.max(class_scores, axis=1)
        
        # Convert boxes from center format to corner format
        x_center, y_center, width, height = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
        x1 = x_center - width / 2
        y1 = y_center - height / 2
        x2 = x_center + width / 2
        y2 = y_center + height / 2
        
        # Scale boxes back to original image coordinates
        x1 = (x1 - pad_w) / scale
        y1 = (y1 - pad_h) / scale
        x2 = (x2 - pad_w) / scale
        y2 = (y2 - pad_h) / scale
        
        # Clip boxes to image boundaries
        x1 = np.clip(x1, 0, w)
        y1 = np.clip(y1, 0, h)
        x2 = np.clip(x2, 0, w)
        y2 = np.clip(y2, 0, h)
        
        # Apply NMS (Non-Maximum Suppression)
        boxes_for_nms = np.column_stack([x1, y1, x2, y2])
        indices = cv2.dnn.NMSBoxes(
            boxes_for_nms.tolist(), 
            confidences.tolist(), 
            conf_threshold, 
            0.4  # NMS threshold
        )
        
        results = []
        if len(indices) > 0:
            for i in indices.flatten():
                results.append([
                    int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i]),
                    float(confidences[i]), int(class_ids[i])
                ])
        
        return results
    
    def draw_results(self, image_path, results, output_path=None):
        """
        Draw detection results on image
        
        Args:
            image_path: input image path
            results: detection results
            output_path: output image path
        """
        img = cv2.imread(image_path)
        
        for result in results:
            x1, y1, x2, y2, confidence, class_id = result
            
            # Get class name
            class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"Class_{class_id}"
            
            # Draw bounding box
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # Draw label
            label = f"{class_name}: {confidence:.3f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
            cv2.rectangle(img, (x1, y1-25), (x1+label_size[0], y1), (0, 255, 0), -1)
            cv2.putText(img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        
        # Save result
        if output_path:
            cv2.imwrite(output_path, img)
            print(f"ðŸ’¾ Result saved: {output_path}")
        
        return img
    
    def __del__(self):
        """Cleanup resources"""
        if hasattr(self, 'rknn'):
            self.rknn.release()

# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™
if __name__ == "__main__":
    # Configuration
    MODEL_PATH = "yolov5s.rknn"
    IMAGE_PATH = "test_image.jpg"
    OUTPUT_PATH = "result.jpg"
    CLASS_NAMES = ["person", "bicycle", "car"]  # YOLOv5 classes
    
    # Initialize NPU inference
    npu = NPUInference(MODEL_PATH, CLASS_NAMES)
    
    # Run inference
    results, inference_time = npu.inference(IMAGE_PATH)
    
    if results:
        print(f"ðŸŽ¯ Found {len(results)} objects")
        
        # Draw and save results
        npu.draw_results(IMAGE_PATH, results, OUTPUT_PATH)
        
        # Print detection details
        for i, result in enumerate(results):
            x1, y1, x2, y2, conf, class_id = result
            class_name = CLASS_NAMES[class_id] if class_id < len(CLASS_NAMES) else f"Class_{class_id}"
            print(f"  [{i+1}] {class_name}: {conf:.3f} at ({x1},{y1},{x2},{y2})")
    else:
        print("âš ï¸ No objects detected")
```

### ðŸš€ à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Script
```bash
# à¸£à¸±à¸™ inference
python3 npu_inference.py

# à¸«à¸£à¸·à¸­à¹ƒà¸Šà¹‰à¸œà¹ˆà¸²à¸™ command line
python3 -c "
from npu_inference import NPUInference
npu = NPUInference('model.rknn', ['class1', 'class2'])
results, time = npu.inference('test.jpg')
print(f'Found {len(results)} objects in {time:.1f}ms')
"
```

---

## âš ï¸ à¸‚à¹‰à¸­à¸ˆà¸³à¸à¸±à¸”à¸•à¸­à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

### ðŸš« Hardware Limitations

#### 1. **Single NPU Core Processing**
```bash
âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ multiple models à¸žà¸£à¹‰à¸­à¸¡à¸à¸±à¸™à¹„à¸”à¹‰
âŒ à¸—à¸³à¸‡à¸²à¸™à¹à¸šà¸š sequential queue à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
âœ… à¹ƒà¸Šà¹‰à¸—à¸£à¸±à¸žà¸¢à¸²à¸à¸£ 100% à¹€à¸¡à¸·à¹ˆà¸­à¸—à¸³à¸‡à¸²à¸™ (binary mode: 0% à¸«à¸£à¸·à¸­ 100%)
```

#### 2. **Memory Constraints**
```bash
âš ï¸ NPU Memory: à¸ˆà¸³à¸à¸±à¸”à¸•à¸²à¸¡à¸‚à¸™à¸²à¸” model
âš ï¸ Model Size: à¸¢à¸´à¹ˆà¸‡à¹ƒà¸«à¸à¹ˆ à¸¢à¸´à¹ˆà¸‡à¹ƒà¸Šà¹‰à¹€à¸§à¸¥à¸² load à¸™à¸²à¸™
âš ï¸ Batch Size: à¹à¸™à¸°à¸™à¸³ batch size = 1 à¸ªà¸³à¸«à¸£à¸±à¸š real-time
```

#### 3. **Model Format Restrictions**
```bash
âœ… à¸£à¸­à¸‡à¸£à¸±à¸š: .rknn format à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
âŒ à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š: .pt, .onnx, .tflite à¹‚à¸”à¸¢à¸•à¸£à¸‡
âŒ Dynamic shapes: à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š dynamic input shapes
```

### ðŸ”§ Software Limitations

#### 1. **RKNN Server Dependencies**
```bash
âš ï¸ à¸•à¹‰à¸­à¸‡à¸¡à¸µ rknn_server running à¹€à¸ªà¸¡à¸­
âš ï¸ à¸«à¸²à¸ server crash = NPU à¹ƒà¸Šà¹‰à¹„à¸¡à¹ˆà¹„à¸”à¹‰
âš ï¸ Restart service: sudo systemctl restart rknn_server
```

#### 2. **Model Conversion Issues**
```bash
âŒ à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸—à¸¸à¸ ONNX model à¹à¸›à¸¥à¸‡à¹„à¸”à¹‰
âŒ Custom operators à¸­à¸²à¸ˆà¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š
âŒ à¸šà¸²à¸‡ activation functions à¹„à¸¡à¹ˆà¸£à¸­à¸‡à¸£à¸±à¸š
âš ï¸ à¸•à¹‰à¸­à¸‡à¹€à¸—à¸ªà¸•à¹Œ model à¸«à¸¥à¸±à¸‡à¹à¸›à¸¥à¸‡à¹€à¸ªà¸¡à¸­
```

#### 3. **Performance Limitations**
```bash
âš ï¸ Model switching: à¹ƒà¸Šà¹‰à¹€à¸§à¸¥à¸² reload model (~1-2 à¸§à¸´à¸™à¸²à¸—à¸µ)
âš ï¸ Concurrent requests: à¸—à¸³à¹ƒà¸«à¹‰à¸Šà¹‰à¸²à¸¥à¸‡à¹€à¸žà¸£à¸²à¸°à¸•à¹‰à¸­à¸‡à¸£à¸­à¸„à¸´à¸§
âš ï¸ Large models: à¸­à¸²à¸ˆà¹ƒà¸Šà¹‰à¹€à¸§à¸¥à¸² inference à¸™à¸²à¸™à¸à¸§à¹ˆà¸² GPU
```

### ðŸ” Debugging Common Issues

#### 1. **NPU à¹„à¸¡à¹ˆà¸—à¸³à¸‡à¸²à¸™**
```bash
# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š RKNN Server
systemctl status rknn_server

# Restart service
sudo systemctl restart rknn_server

# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š NPU frequency
cat /sys/class/devfreq/fdab0000.npu/cur_freq
```

#### 2. **Model Load à¹„à¸¡à¹ˆà¹„à¸”à¹‰**
```bash
# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œ .rknn
ls -la model.rknn

# à¸—à¸”à¸ªà¸­à¸š model
python3 -c "
from rknn import RKNN
rknn = RKNN()
ret = rknn.load_rknn('model.rknn')
print('Load result:', ret)
rknn.release()
"
```

#### 3. **Performance à¸Šà¹‰à¸²**
```bash
# à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š NPU governor
cat /sys/class/devfreq/fdab0000.npu/governor

# à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ performance mode
echo performance | sudo tee /sys/class/devfreq/fdab0000.npu/governor
```

### ðŸ’¡ Best Practices

#### 1. **Model Optimization**
```bash
âœ… à¹ƒà¸Šà¹‰ FP16 quantization à¸ªà¸³à¸«à¸£à¸±à¸š balance à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ speed/accuracy
âœ… à¹ƒà¸Šà¹‰ INT8 quantization à¸ªà¸³à¸«à¸£à¸±à¸š maximum speed
âœ… à¹€à¸à¹‡à¸š model files à¹ƒà¸™ fast storage (SSD)
```

#### 2. **Application Design**
```bash
âœ… Load model 1 à¸„à¸£à¸±à¹‰à¸‡, à¹ƒà¸Šà¹‰à¸«à¸¥à¸²à¸¢à¸„à¸£à¸±à¹‰à¸‡
âœ… à¹ƒà¸Šà¹‰ batch processing à¹à¸—à¸™ concurrent requests
âœ… Implement proper error handling à¸ªà¸³à¸«à¸£à¸±à¸š NPU failures
```

#### 3. **Performance Monitoring**
```bash
# à¸•à¸´à¸”à¸•à¸²à¸¡ NPU usage
watch -n 1 'cat /sys/class/devfreq/fdab0000.npu/cur_freq'

# à¸•à¸´à¸”à¸•à¸²à¸¡ memory usage
htop

# à¸•à¸´à¸”à¸•à¸²à¸¡ inference time
time python3 npu_inference.py
```

---

## ðŸ“Š Performance Benchmarks

### ðŸŽ¯ Typical Performance (RK3588 NPU)

| Model Type | Input Size | FP32 | FP16 | INT8 |
|------------|------------|------|------|------|
| **YOLOv5s** | 640x640 | 75ms | 65ms | 45ms |
| **YOLOv5m** | 640x640 | 120ms | 95ms | 70ms |
| **YOLOv5l** | 640x640 | 180ms | 140ms | 100ms |

### ðŸ“ˆ Throughput Comparison

```bash
NPU (RK3588):     13-22 FPS (depending on model size)
CPU (A76 cores):  2-5 FPS (same models)
GPU (Mali-G610):  8-12 FPS (same models)

ðŸ† NPU Winner: 2-4x faster than CPU, 1.5-2x faster than GPU
```

---

## ðŸŽ¯ à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ RKNN NPU

### âœ… à¸ˆà¸¸à¸”à¹à¸‚à¹‡à¸‡
- **Performance**: à¹€à¸£à¹‡à¸§à¸à¸§à¹ˆà¸² CPU/GPU à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸±à¸”à¹€à¸ˆà¸™
- **Power Efficiency**: à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¹„à¸Ÿà¸à¸§à¹ˆà¸² GPU
- **Offline Operation**: à¸—à¸³à¸‡à¸²à¸™à¹„à¸”à¹‰ 100% à¹à¸šà¸š offline
- **Edge Computing**: à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸š embedded applications

### âš ï¸ à¸‚à¹‰à¸­à¸„à¸§à¸£à¸£à¸°à¸§à¸±à¸‡
- **Single Task**: à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸—à¸µà¸¥à¸° model à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
- **Format Dependency**: à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ .rknn format à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
- **Server Dependency**: à¸žà¸¶à¹ˆà¸‡ rknn_server service
- **Limited Flexibility**: à¸™à¹‰à¸­à¸¢à¸à¸§à¹ˆà¸² GPU à¹ƒà¸™à¹€à¸£à¸·à¹ˆà¸­à¸‡ customization

### ðŸš€ à¹à¸™à¸°à¸™à¸³à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™
1. **à¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸š Production Inference**: à¹€à¸£à¹‡à¸§à¹à¸¥à¸°à¸›à¸£à¸°à¸«à¸¢à¸±à¸”à¹„à¸Ÿ
2. **à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸š Training**: NPU à¸ªà¸³à¸«à¸£à¸±à¸š inference à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
3. **à¹€à¸«à¸¡à¸²à¸°à¸ªà¸³à¸«à¸£à¸±à¸š Edge Devices**: à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£ real-time processing
4. **à¸—à¸”à¸ªà¸­à¸š Model à¸à¹ˆà¸­à¸™à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸£à¸´à¸‡**: à¹€à¸žà¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š accuracy à¸«à¸¥à¸±à¸‡à¹à¸›à¸¥à¸‡

---

## ðŸ“š Additional Resources

### ðŸ”— Documentation Links
- [Firefly NPU Usage Guide](https://wiki.t-firefly.com/en/EC-R3588SPC/usage_npu.html)
- [RKNN Toolkit2 Documentation](https://github.com/rockchip-linux/rknn-toolkit2)
- [RK3588 NPU Performance Guide](https://wiki.t-firefly.com/en/EC-R3588SPC/)

### ðŸ› ï¸ Tools à¹à¸¥à¸° Scripts
- `onnx_to_rknn_converter.py`: ONNX â†’ RKNN converter
- `npu_inference.py`: NPU inference tool
- `npu_monitor.py`: Performance monitoring tool
- `batch_npu_inference.py`: Batch processing tool

### ðŸ“ž Support
à¸ªà¸³à¸«à¸£à¸±à¸šà¸›à¸±à¸à¸«à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ à¸ªà¸²à¸¡à¸²à¸£à¸–à¸”à¸¹ logs à¹„à¸”à¹‰à¸—à¸µà¹ˆ:
```bash
# RKNN Server logs
journalctl -u rknn_server -f

# System logs
dmesg | grep -i npu

# Performance logs
cat /sys/class/devfreq/fdab0000.npu/load
```

---

**ðŸ“ Document Version**: 1.0  
**ðŸ“… Last Updated**: October 29, 2025  
**ðŸ‘¨â€ðŸ’» Author**: YOLO NPU Implementation Team  
**ðŸ¢ Hardware**: EC-R3588SPC (RK3588 SoC, 6 TOPS NPU)
