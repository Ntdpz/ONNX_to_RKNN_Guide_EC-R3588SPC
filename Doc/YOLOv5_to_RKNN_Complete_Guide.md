# YOLOv5 to RKNN Complete Conversion Guide

‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÅ‡∏õ‡∏•‡∏á YOLOv5 model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤‡∏à‡∏≤‡∏Å Windows ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏ô NPU (RKNN) ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£

## üìã Overview

‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á YOLOv5 model ‡∏à‡∏≤‡∏Å Windows-trained format ‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô RKNN format ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏ô RK3588 NPU ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ 3 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å:

1. **Windows Model ‚Üí PyTorch (PT)** - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç path compatibility
2. **PyTorch (PT) ‚Üí ONNX** - Export ‡πÄ‡∏õ‡πá‡∏ô standard format
3. **ONNX ‚Üí RKNN** - ‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NPU acceleration

## üõ†Ô∏è Prerequisites

### Environment Setup
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python environment
source /home/firefly/Documents/YOLO/.venv/bin/activate

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö RKNN toolkit
python -c "import rknn; print('RKNN toolkit available')"
```

### Required Files
- Windows-trained YOLOv5 model: `runs/train/[model_name]/weights/best.pt`
- YOLOv5 export script: `/home/firefly/Documents/YOLO/yolov5/export.py`
- Universal RKNN converter: `/home/firefly/Documents/YOLO/Convert_tools/universal_onnx_to_rknn.py`

## üìÇ Directory Structure

```
/home/firefly/Documents/YOLO/
‚îú‚îÄ‚îÄ yolov5/
‚îÇ   ‚îú‚îÄ‚îÄ export.py
‚îÇ   ‚îî‚îÄ‚îÄ runs/train/[model_name]/weights/best.pt
‚îú‚îÄ‚îÄ model-final-V2/
‚îÇ   ‚îú‚îÄ‚îÄ PT/           # PyTorch models
‚îÇ   ‚îú‚îÄ‚îÄ ONNX/         # ONNX models
‚îÇ   ‚îî‚îÄ‚îÄ RKNN/         # RKNN models
‚îî‚îÄ‚îÄ Convert_tools/
    ‚îî‚îÄ‚îÄ universal_onnx_to_rknn.py
```

## üîÑ Step-by-Step Conversion Process

### Step 1: Windows Model to PyTorch (PT)

**Problem**: Windows-trained models ‡∏°‡∏µ path format ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö Linux

**Solution**: ‡πÉ‡∏ä‡πâ pathlib monkey patching

```bash
cd /home/firefly/Documents/YOLO/yolov5

# ‡πÅ‡∏õ‡∏•‡∏á Vehicle Type Detection Model
PYTHONPATH=/home/firefly/Documents/YOLO:$PYTHONPATH /home/firefly/Documents/YOLO/.venv/bin/python -c "
import pathlib
import platform
if platform.system() != 'Windows':
    import posixpath
    pathlib.PurePath._flavour = pathlib._posix_flavour
    pathlib.WindowsPath = pathlib.PosixPath

import torch
checkpoint = torch.load('runs/train/vehicle_type_detection_cuda/weights/best.pt', map_location='cpu')
torch.save(checkpoint, '/home/firefly/Documents/YOLO/model-final-V2/PT/vehicle_type_detection.pt')
print('‚úÖ Vehicle type detection model exported to PT format')
print('üìÅ Location: /home/firefly/Documents/YOLO/model-final-V2/PT/vehicle_type_detection.pt')
"
```

**Alternative Script Method**:
```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ
/home/firefly/Documents/YOLO/.venv/bin/python /home/firefly/Documents/YOLO/export_vehicle_alternative.py
```

**‚ö†Ô∏è Important PT Model Format Requirements**:

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö models ‡∏ó‡∏µ‡πà‡∏°‡∏µ architecture ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô (‡πÄ‡∏ä‡πà‡∏ô license plate detection) ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô **fused layers format** ‡∏Å‡πà‡∏≠‡∏ô export ‡πÄ‡∏õ‡πá‡∏ô ONNX:

```bash
# 1. ‡πÅ‡∏õ‡∏•‡∏á Windows model ‡πÄ‡∏õ‡πá‡∏ô PT format ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
cd /home/firefly/Documents/YOLO/yolov5
PYTHONPATH=/home/firefly/Documents/YOLO:$PYTHONPATH /home/firefly/Documents/YOLO/.venv/bin/python -c "
import pathlib
import platform
if platform.system() != 'Windows':
    import posixpath
    pathlib.PurePath._flavour = pathlib._posix_flavour
    pathlib.WindowsPath = pathlib.PosixPath

import torch
checkpoint = torch.load('runs/train/license_plate_model_87percent/weights/best.pt', map_location='cpu')
torch.save(checkpoint, '/home/firefly/Documents/YOLO/model-final-V2/PT/license_plate_model_87percent.pt')
print('‚úÖ License plate model exported to PT format')
"

# 2. ‡πÅ‡∏õ‡∏•‡∏á PT ‡πÄ‡∏õ‡πá‡∏ô fused layers format
/home/firefly/Documents/YOLO/.venv/bin/python -c "
import torch
import sys
sys.path.append('.')
from models.experimental import attempt_load
from utils.torch_utils import select_device

# Load model and fuse layers
device = select_device('cpu')
model = attempt_load('/home/firefly/Documents/YOLO/model-final-V2/PT/license_plate_model_87percent.pt', device=device, inplace=True, fuse=True)
model.eval()

# Save fused model
torch.save({
    'model': model,
    'epoch': -1,
    'best_fitness': None,
    'training_results': None,
    'optimizer': None
}, '/home/firefly/Documents/YOLO/model-final-V2/PT/license_plate_model_87percent_fused.pt')

print('‚úÖ Fused model saved successfully')
"
```

**PT Model Format Types**:
- **Standard PT**: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö models ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô (vehicle detection, basic object detection)
- **Fused PT**: ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö models ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô (license plate detection, custom architectures)
- **Fused layers** ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô channel mismatch errors ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ONNX export

### Step 2: PyTorch (PT) to ONNX

**Export ‡πÄ‡∏õ‡πá‡∏ô ONNX format** ‡∏û‡∏£‡πâ‡∏≠‡∏° optimization:

```bash
cd /home/firefly/Documents/YOLO/yolov5

# Export Vehicle Type Detection to ONNX
/home/firefly/Documents/YOLO/.venv/bin/python export.py \
    --weights /home/firefly/Documents/YOLO/model-final-V2/PT/vehicle_type_detection.pt \
    --include onnx \
    --opset 12 \
    --simplify \
    --device cpu
```

**Parameters Explanation**:
- `--weights`: Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á PT model
- `--include onnx`: Export format ‡πÄ‡∏õ‡πá‡∏ô ONNX
- `--opset 12`: ONNX opset version (compatible ‡∏Å‡∏±‡∏ö RKNN)
- `--simplify`: ‡∏ó‡∏≥ graph optimization
- `--device cpu`: ‡πÉ‡∏ä‡πâ CPU ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö export (stable ‡∏Å‡∏ß‡πà‡∏≤)

### Step 3: ONNX to RKNN

**‡πÉ‡∏ä‡πâ Universal RKNN Converter** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô NPU format:

#### FP32 Strategy (Highest Accuracy)
```bash
cd /home/firefly/Documents/YOLO/Convert_tools

/home/firefly/Documents/YOLO/.venv/bin/python universal_onnx_to_rknn.py \
    --input /home/firefly/Documents/YOLO/model-final-V2/ONNX/vehicle_type_detection.onnx \
    --output /home/firefly/Documents/YOLO/model-final-V2/RKNN/vehicle_type_detection_fp32.rknn \
    --strategy fp32 \
    --verbose
```

#### FP16 Strategy (Balanced)
```bash
/home/firefly/Documents/YOLO/.venv/bin/python universal_onnx_to_rknn.py \
    --input /home/firefly/Documents/YOLO/model-final-V2/ONNX/vehicle_type_detection.onnx \
    --output /home/firefly/Documents/YOLO/model-final-V2/RKNN/vehicle_type_detection_fp16.rknn \
    --strategy fp16 \
    --verbose
```

#### Auto Strategy (Try Best First)
```bash
/home/firefly/Documents/YOLO/.venv/bin/python universal_onnx_to_rknn.py \
    --input /home/firefly/Documents/YOLO/model-final-V2/ONNX/vehicle_type_detection.onnx \
    --output /home/firefly/Documents/YOLO/model-final-V2/RKNN/vehicle_type_detection_auto.rknn \
    --strategy auto \
    --verbose
```

## üìä Model Size Comparison

| Format | Size | Accuracy | NPU Acceleration |
|--------|------|----------|------------------|
| PT     | ~13.8 MB | Original | ‚ùå |
| ONNX   | ~27.3 MB | Original | ‚ùå |
| RKNN FP32 | ~15.2 MB | High | ‚úÖ |
| RKNN FP16 | ~15.2 MB | High | ‚úÖ |

## üß™ Example: Complete Vehicle Type Detection Conversion

### 1. Setup Environment
```bash
cd /home/firefly/Documents/YOLO
source .venv/bin/activate
```

### 2. Convert Windows Model to PT
```bash
cd yolov5
PYTHONPATH=/home/firefly/Documents/YOLO:$PYTHONPATH /home/firefly/Documents/YOLO/.venv/bin/python -c "
import pathlib
import platform
if platform.system() != 'Windows':
    import posixpath
    pathlib.PurePath._flavour = pathlib._posix_flavour
    pathlib.WindowsPath = pathlib.PosixPath

import torch
checkpoint = torch.load('runs/train/vehicle_type_detection_cuda/weights/best.pt', map_location='cpu')
torch.save(checkpoint, '/home/firefly/Documents/YOLO/model-final-V2/PT/vehicle_type_detection.pt')
print('‚úÖ Model exported to PT format')
"
```

### 3. Export PT to ONNX
```bash
/home/firefly/Documents/YOLO/.venv/bin/python export.py \
    --weights /home/firefly/Documents/YOLO/model-final-V2/PT/vehicle_type_detection.pt \
    --include onnx \
    --opset 12 \
    --simplify
```

### 4. Convert ONNX to RKNN
```bash
cd /home/firefly/Documents/YOLO/Convert_tools
/home/firefly/Documents/YOLO/.venv/bin/python universal_onnx_to_rknn.py \
    --input /home/firefly/Documents/YOLO/model-final-V2/ONNX/vehicle_type_detection.onnx \
    --output /home/firefly/Documents/YOLO/model-final-V2/RKNN/vehicle_type_detection.rknn \
    --strategy fp32 \
    --verbose
```

### 5. Verify Results
```bash
ls -la /home/firefly/Documents/YOLO/model-final-V2/RKNN/
# Expected: vehicle_type_detection.rknn (~15.2 MB)
```

## üîß Universal RKNN Converter Usage

### Available Strategies

| Strategy | Description | Use Case |
|----------|-------------|----------|
| `fp32` | 32-bit floating point | Highest accuracy |
| `fp16` | 16-bit floating point | Balanced accuracy/performance |
| `int8` | 8-bit integer quantization | Smallest size, fastest |
| `hybrid` | Mixed precision | Optimal balance |
| `auto` | Try strategies in order | Automatic best result |

### Command Options
```bash
python universal_onnx_to_rknn.py [OPTIONS]

Options:
  --input, -i      Input ONNX model file
  --output, -o     Output RKNN file path
  --strategy, -s   Conversion strategy [fp32/fp16/int8/hybrid/auto]
  --dataset, -d    Dataset file for quantization (INT8/hybrid only)
  --verbose, -v    Verbose output
  --log, -l        Save conversion log to file
```

### Batch Conversion
```bash
python universal_onnx_to_rknn.py \
    --batch /path/to/onnx/directory \
    --output_dir /path/to/rknn/directory \
    --strategy auto
```

## ‚ö†Ô∏è Common Issues & Solutions

### Issue 1: WindowsPath Error
```
AttributeError: module 'pathlib' has no attribute 'WindowsPath'
```
**Solution**: ‡πÉ‡∏ä‡πâ pathlib monkey patching ‡∏ï‡∏≤‡∏° Step 1

### Issue 2: RKNN Quantization Error
```
quantized_dtype 'dynamic_fixed_point-i16' not supported
```
**Solution**: ‡πÉ‡∏ä‡πâ universal converter ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RKNN toolkit 2.3.0

### Issue 3: ONNX Export Error
```
RuntimeError: Exporting the operator to ONNX opset version 11 is not supported
```
**Solution**: ‡πÉ‡∏ä‡πâ `--opset 12` ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤

### Issue 4: Channel Mismatch Error during ONNX Export
```
RuntimeError: Given groups=1, weight of size [48, 12, 3, 3], expected input[1, 48, 320, 320] to have 12 channels, but got 48 channels instead
```
**Solution**: ‡πÅ‡∏õ‡∏•‡∏á PT model ‡πÄ‡∏õ‡πá‡∏ô fused layers format ‡∏Å‡πà‡∏≠‡∏ô export:

```bash
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö models ‡∏ó‡∏µ‡πà‡∏°‡∏µ architecture ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ fused format
cd /home/firefly/Documents/YOLO/yolov5
/home/firefly/Documents/YOLO/.venv/bin/python -c "
import torch
import sys
sys.path.append('.')

# Load fused model
checkpoint = torch.load('/path/to/fused_model.pt', map_location='cpu')
model = checkpoint['model']
model.eval()

# Export using torch.onnx.export directly
dummy_input = torch.randn(1, 3, 640, 640)
torch.onnx.export(
    model,
    dummy_input,
    '/path/to/output.onnx',
    export_params=True,
    opset_version=12,
    do_constant_folding=True,
    input_names=['images'],
    output_names=['output']
)
"
```

## üöÄ Performance Optimization Tips

### 1. Model Size Optimization
- ‡πÉ‡∏ä‡πâ `--simplify` ‡πÄ‡∏°‡∏∑‡πà‡∏≠ export ONNX
- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å strategy ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
- ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ INT8 quantization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö production

### 2. NPU Utilization
- RKNN models ‡∏à‡∏∞‡πÉ‡∏ä‡πâ NPU acceleration ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- Monitor NPU usage ‡∏î‡πâ‡∏ß‡∏¢ `sudo cat /sys/kernel/debug/rknpu/load`

### 3. Inference Speed
- FP16 ‡∏°‡∏±‡∏Å‡πÉ‡∏´‡πâ performance ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ö‡∏ô RK3588
- INT8 ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡∏•‡∏î accuracy

## üìù File Naming Convention

```
model_name_[strategy].rknn

Examples:
- vehicle_type_detection_fp32.rknn
- license_plate_detection_fp16.rknn
- object_detection_int8.rknn
```

## üîç Verification Commands

### Check Model Information
```bash
# PT model info
python -c "import torch; print(torch.load('model.pt', map_location='cpu').keys())"

# ONNX model info
python -c "import onnx; model = onnx.load('model.onnx'); print(f'Inputs: {len(model.graph.input)}, Outputs: {len(model.graph.output)}')"
```

### Test RKNN Model
```bash
# Basic RKNN model loading test
python -c "
from rknn.api import RKNN
rknn = RKNN()
ret = rknn.load_rknn('model.rknn')
print('‚úÖ RKNN model loaded successfully' if ret == 0 else '‚ùå Failed to load RKNN model')
rknn.release()
"
```

## üìö Additional Resources

- [YOLOv5 Official Documentation](https://github.com/ultralytics/yolov5)
- [RKNN Toolkit Documentation](https://github.com/rockchip-linux/rknn-toolkit2)
- [RK3588 NPU Performance Guide](https://wiki.radxa.com/Rock5/guide/rknn)

---

**Last Updated**: October 27, 2025  
**Compatible**: RKNN Toolkit 2.3.0, YOLOv5 7.0+, RK3588 NPU