# üöÄ Universal ONNX to RKNN Converter - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

## üìã Overview

**Universal ONNX to RKNN Converter** ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á ONNX Model ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏õ‡πá‡∏ô RKNN Format ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö Auto-detection ‡πÅ‡∏•‡∏∞ Configuration ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á

### ‚ú® Features

- ‚úÖ **Auto-detect Model Type** - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå YOLOv5/v8/v10 ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- ‚úÖ **Full Configuration** - ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å parameter
- ‚úÖ **Multi-Platform Support** - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö RK3588, RK3576, RK3562, RV1109/1126, RK1808, RK3399Pro
- ‚úÖ **Flexible Quantization** - FP16, INT8, UINT8 + Multiple algorithms
- ‚úÖ **Smart Recommendations** - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ preprocessing/postprocessing ‡∏ï‡∏≤‡∏° model type
- ‚úÖ **Verification System** - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö model ‡∏´‡∏•‡∏±‡∏á convert

---

## üì¶ Requirements

### ‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡πÅ‡∏ß‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ

```bash
# Python
Python >= 3.8

# Libraries
rknn-toolkit2 >= 2.0.0
onnx >= 1.12.0
numpy >= 1.19.0
```

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á RKNN-Toolkit2
pip3 install rknn-toolkit2

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á ONNX
pip3 install onnx

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á NumPy
pip3 install numpy
```

### ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

```bash
python3 -c "from rknn.api import RKNN; print('RKNN OK')"
python3 -c "import onnx; print('ONNX OK')"
```

---

## üöÄ Quick Start

### 1. Basic FP16 Conversion (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)

```bash
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_fp16.rknn
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- Model RKNN ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ FP16 quantization
- Accuracy ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á ONNX ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡∏£‡∏∂‡πà‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡∏≠‡∏á FP32

### 2. INT8 Quantization (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Performance)

```bash
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_int8.rknn \
    --quantize \
    --dataset dataset.txt
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- Model RKNN ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ INT8 quantization
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô 2-4 ‡πÄ‡∏ó‡πà‡∏≤
- ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á 60-70%
- Accuracy ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (1-5%)

### 3. With Verification

```bash
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model.rknn \
    --verify
```

**‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:**
- Model ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
- Runtime initialization (‡∏ö‡∏ô target platform)

---

## üìñ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### Example 1: YOLOv8 Object Detection (Basic)

```bash
python3 universal_onnx_to_rknn.py \
    --onnx yolov8n.onnx \
    --rknn yolov8n_fp16.rknn \
    --platform rk3588
```

**Output:**
```
üîç Analyzing ONNX model...
   üìù Graph Name: torch_jit
   üìê Input Shape: [1, 3, 640, 640]
   üìä Output Shapes:
      [0] output0: [1, 84, 8400]
   üéØ Detected Type: YOLOv8

üìã Conversion Settings:
   üìÅ Input:  yolov8n.onnx
   üíæ Output: yolov8n_fp16.rknn
   üéØ Platform: rk3588
   üîß Quantization: FP16
   ‚ö° Optimization Level: 3

‚úÖ Conversion completed successfully!

üí° Recommendations for YOLOv8:
   Preprocessing:
   - Use Letterbox resize (maintain aspect ratio)
   - Padding with gray color (114, 114, 114)
   - Convert BGR ‚Üí RGB
   - Normalize: mean=[0,0,0], std=[255,255,255]
```

### Example 2: YOLOv8 with INT8 Quantization

```bash
python3 universal_onnx_to_rknn.py \
    --onnx yolov8n.onnx \
    --rknn yolov8n_int8.rknn \
    --quantize \
    --dataset coco_calibration.txt \
    --algorithm mmse \
    --verify
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- `--quantize`: ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô INT8 quantization
- `--dataset`: ‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö calibration (500-1000 ‡∏£‡∏π‡∏õ)
- `--algorithm mmse`: ‡πÉ‡∏ä‡πâ MMSE algorithm (accuracy ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ normal)
- `--verify`: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö model ‡∏´‡∏•‡∏±‡∏á convert

### Example 3: Custom Normalization

```bash
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model.rknn \
    --mean 123.675 116.28 103.53 \
    --std 58.395 57.12 57.375
```

**Use case:**
- Model ‡∏ó‡∏µ‡πà train ‡∏î‡πâ‡∏ß‡∏¢ ImageNet normalization
- Custom preprocessing pipeline

### Example 4: Different Platform (RK3576)

```bash
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_rk3576.rknn \
    --platform rk3576 \
    --quantize \
    --dataset dataset.txt
```

### Example 5: Advanced Configuration

```bash
python3 universal_onnx_to_rknn.py \
    --onnx yolov8s.onnx \
    --rknn yolov8s_hybrid.rknn \
    --platform rk3588 \
    --quantize \
    --dtype INT8 \
    --algorithm kl_divergence \
    --method channel \
    --dataset dataset.txt \
    --optimization 3 \
    --mean 0 0 0 \
    --std 255 255 255 \
    --hybrid-quant \
    --hybrid-quant-file hybrid_config.txt \
    --custom-string "v1.0.0-production" \
    --verify \
    --verbose
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- `--dtype INT8`: ‡∏£‡∏∞‡∏ö‡∏∏ data type ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö quantization
- `--algorithm kl_divergence`: ‡πÉ‡∏ä‡πâ KL Divergence algorithm
- `--method channel`: Quantize ‡πÅ‡∏ö‡∏ö per-channel (accuracy ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ per-layer)
- `--optimization 3`: Optimization ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
- `--hybrid-quant`: Mix FP16 ‡πÅ‡∏•‡∏∞ INT8 (layers ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ä‡πâ FP16)
- `--custom-string`: ‡πÄ‡∏û‡∏¥‡πà‡∏° version tag
- `--verbose`: ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• debug ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î

---

## ‚öôÔ∏è Parameters Reference

### Required Parameters

| Parameter | Short | Type | Description |
|-----------|-------|------|-------------|
| `--onnx` | `-i` | string | Path to input ONNX model file |
| `--rknn` | `-o` | string | Path to output RKNN model file |

### Platform Settings

| Parameter | Short | Default | Choices | Description |
|-----------|-------|---------|---------|-------------|
| `--platform` | `-p` | `rk3588` | rk3588, rk3576, rk3562, rv1109, rv1126, rk1808, rk3399pro | Target platform |
| `--sub-platform` | - | `None` | - | Sub-platform for specific chip variants |

### Quantization Settings

| Parameter | Short | Default | Choices | Description |
|-----------|-------|---------|---------|-------------|
| `--quantize` | `-q` | `False` | - | Enable quantization (INT8) |
| `--dtype` | - | `INT8` | INT8, FP16, UINT8 | Quantization data type |
| `--algorithm` | - | `normal` | normal, mmse, kl_divergence | Quantization algorithm |
| `--method` | - | `channel` | channel, layer | Quantization method |
| `--dataset` | `-d` | `None` | - | Path to dataset.txt for calibration |

### Optimization Settings

| Parameter | Short | Default | Range | Description |
|-----------|-------|---------|-------|-------------|
| `--optimization` | - | `3` | 0-3 | Optimization level (higher = more optimized) |

### Model Settings

| Parameter | Short | Format | Example | Description |
|-----------|-------|--------|---------|-------------|
| `--mean` | - | R G B | `--mean 0 0 0` | Mean values for normalization |
| `--std` | - | R G B | `--std 255 255 255` | Std values for normalization |
| `--input-size` | - | C H W | `--input-size 3 640 640` | Input size (auto-detected if omitted) |
| `--outputs` | - | list | `--outputs output0 output1` | Output layer names (auto-detected if omitted) |

### Advanced Settings

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--hybrid-quant` | `False` | Enable hybrid quantization (mix FP16+INT8) |
| `--hybrid-quant-file` | `None` | Path to hybrid quantization config file |
| `--custom-string` | `None` | Custom string for model version tracking |

### Other Options

| Parameter | Short | Default | Description |
|-----------|-------|---------|-------------|
| `--verify` | `-v` | `False` | Verify model after conversion |
| `--verbose` | - | `False` | Enable verbose output |

---

## üìä Quantization Algorithm Comparison

### Normal (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)

```bash
--algorithm normal
```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- ‚úÖ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
- ‚úÖ Accuracy ‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö model ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è Accuracy ‡∏≠‡∏≤‡∏à‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ algorithm ‡∏≠‡∏∑‡πà‡∏ô

**Use case:**
- Prototyping
- Model ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ convert

### MMSE (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Accuracy)

```bash
--algorithm mmse
```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ Accuracy ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ normal
- ‚úÖ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö complex model
- ‚úÖ ‡∏•‡∏î quantization error ‡πÑ‡∏î‡πâ‡∏î‡∏µ

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ normal (2-3 ‡πÄ‡∏ó‡πà‡∏≤)
- ‚ö†Ô∏è ‡πÉ‡∏ä‡πâ memory ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤

**Use case:**
- Production deployment
- Model ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ accuracy ‡∏™‡∏π‡∏á
- YOLOv8, Complex architectures

### KL Divergence (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö specific cases)

```bash
--algorithm kl_divergence
```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
- ‚úÖ ‡∏î‡∏µ‡∏Å‡∏±‡∏ö model ‡∏ó‡∏µ‡πà‡∏°‡∏µ activation ‡πÅ‡∏õ‡∏•‡∏Å‡πÜ
- ‚úÖ Handle outliers ‡πÑ‡∏î‡πâ‡∏î‡∏µ

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
- ‚ö†Ô∏è ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å
- ‚ö†Ô∏è ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ MMSE ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á case

**Use case:**
- Model ‡∏ó‡∏µ‡πà‡∏°‡∏µ extreme values
- Classification tasks
- Research purposes

---

## üìÅ Dataset Preparation (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö INT8)

### ‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î Dataset

1. **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ:** 500-1000 ‡∏£‡∏π‡∏õ (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
2. **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:** JPG, PNG, BMP
3. **‡∏Ç‡∏ô‡∏≤‡∏î:** ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î (‡∏à‡∏∞ resize ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
4. **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢:** ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å use case

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset.txt

#### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Manual

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå dataset.txt
nano dataset.txt
```

```
/path/to/image1.jpg
/path/to/image2.jpg
/path/to/image3.jpg
...
```

#### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Script (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

```bash
# ‡πÉ‡∏ä‡πâ create_dataset_txt.py
python3 create_dataset_txt.py \
    -i /path/to/images \
    -o dataset.txt \
    -n 1000
```

#### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: Command Line

```bash
# Linux/Mac
find /path/to/images -name "*.jpg" | head -1000 > dataset.txt

# ‡πÉ‡∏ä‡πâ absolute path
find "$(pwd)/images" -name "*.jpg" | head -1000 > dataset.txt
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á dataset.txt ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

```
/home/user/dataset/train/img_001.jpg
/home/user/dataset/train/img_002.jpg
/home/user/dataset/train/img_003.jpg
/home/user/dataset/val/img_001.jpg
/home/user/dataset/val/img_002.jpg
```

### Best Practices

- ‚úÖ ‡πÉ‡∏ä‡πâ **absolute path** (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà relative path)
- ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ**‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢** ‡∏à‡∏≤‡∏Å training set
- ‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô **500-1000 ‡∏£‡∏π‡∏õ** (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ)
- ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path **‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á** (‡πÑ‡∏°‡πà‡∏°‡∏µ typo)
- ‚ùå ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ test set (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô data leakage)

---

## üéØ Platform-Specific Guides

### RK3588 (EC-R3588SPC, Orange Pi 5, etc.)

```bash
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model.rknn \
    --platform rk3588 \
    --quantize \
    --dataset dataset.txt
```

**Hardware:**
- NPU: 6 TOPS @ 1GHz
- Cores: 3x NPU cores
- Memory: Shared with system

**Recommendations:**
- Optimization level: **3** (maximum)
- Quantization: **INT8** for best performance
- Algorithm: **mmse** for accuracy

### RK3576

```bash
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model.rknn \
    --platform rk3576
```

**Hardware:**
- NPU: 6 TOPS
- Latest generation NPU

### RV1109/RV1126 (Embedded Vision)

```bash
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model.rknn \
    --platform rv1126 \
    --quantize \
    --dtype INT8
```

**Hardware:**
- NPU: 2 TOPS
- Limited memory

**Recommendations:**
- **‡∏ï‡πâ‡∏≠‡∏á**‡πÉ‡∏ä‡πâ INT8 (FP16 ‡∏à‡∏∞‡∏ä‡πâ‡∏≤)
- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡πÄ‡∏•‡πá‡∏Å‡πÜ (YOLOv8n, YOLOv5s)
- Optimization level: **3**

---

## üîç Auto-Detection Examples

### YOLOv8 Detection

**ONNX Info:**
- Input: `(1, 3, 640, 640)`
- Output: `(1, 84, 8400)`

**Auto-detected Settings:**
```
‚úÖ Detected: YOLOv8
   
üí° Recommendations:
   - Preprocessing: Letterbox + RGB
   - Confidence: 0.25
   - IoU: 0.7-0.85
   - NMS: Required
```

### YOLOv5 Detection

**ONNX Info:**
- Input: `(1, 3, 640, 640)`
- Output: `(1, 25200, 85)`

**Auto-detected Settings:**
```
‚úÖ Detected: YOLOv5
   
üí° Recommendations:
   - Preprocessing: Letterbox + RGB
   - Confidence: 0.25-0.5
   - IoU: 0.45-0.7
   - NMS: Required
```

### YOLOv10 Detection

**ONNX Info:**
- Input: `(1, 3, 640, 640)`
- Output: `(1, 300, 6)`

**Auto-detected Settings:**
```
‚úÖ Detected: YOLOv10
   
üí° Recommendations:
   - Preprocessing: Letterbox + RGB
   - NMS: Not required (built-in)
```

---

## üêõ Troubleshooting

### ‚ùå Error: "Failed to load ONNX model"

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
- ‡πÑ‡∏ü‡∏•‡πå ONNX ‡πÄ‡∏™‡∏µ‡∏¢
- ONNX version ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
- Operators ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ONNX
python3 -c "import onnx; model = onnx.load('model.onnx'); onnx.checker.check_model(model)"

# Export ONNX ‡πÉ‡∏´‡∏°‡πà (PyTorch)
torch.onnx.export(model, dummy_input, 'model.onnx', opset_version=11)
```

### ‚ùå Error: "Build failed"

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
- Dataset path ‡∏ú‡∏¥‡∏î
- Memory ‡πÑ‡∏°‡πà‡∏û‡∏≠
- Operators ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dataset
head -5 dataset.txt
ls -l $(head -1 dataset.txt)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å

# ‡∏•‡∏î optimization level
--optimization 2  # ‡∏à‡∏≤‡∏Å 3

# ‡πÉ‡∏ä‡πâ FP16 ‡πÅ‡∏ó‡∏ô INT8
# ‡∏•‡∏ö --quantize flag
```

### ‚ö†Ô∏è Warning: "Runtime initialization failed"

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏:**
- ‡∏£‡∏±‡∏ô verify ‡∏ö‡∏ô x86 platform (‡∏õ‡∏Å‡∏ï‡∏¥)

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ! ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏Å‡∏ï‡∏¥‡∏ö‡∏ô x86
- Model ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ö‡∏ô RK3588 hardware

### ‚ùå Error: "Dataset file not found"

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
```bash
# ‡πÉ‡∏ä‡πâ absolute path
pwd  # ‡∏î‡∏π current directory
# ‡πÅ‡∏Å‡πâ dataset.txt ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ full path
```

### üìä Model Size ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** RKNN model ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤ ONNX

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ:**
```bash
# ‡πÉ‡∏ä‡πâ INT8 quantization
--quantize --dataset dataset.txt

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î
ls -lh model.onnx model.rknn
```

**Expected sizes:**
- FP32 ONNX: 12 MB ‚Üí FP16 RKNN: 7.6 MB (60%)
- FP32 ONNX: 12 MB ‚Üí INT8 RKNN: 4.7 MB (40%)

---

## üìà Performance Optimization

### 1. Quantization Strategy

**Development Phase:**
```bash
# ‡πÉ‡∏ä‡πâ FP16 - Accuracy ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_fp16.rknn
```

**Production Phase:**
```bash
# ‡πÉ‡∏ä‡πâ INT8 - Performance ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_int8.rknn \
    --quantize \
    --algorithm mmse \
    --dataset dataset.txt
```

### 2. Optimization Level

**Testing:**
```bash
--optimization 1  # ‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡πÅ‡∏ï‡πà performance ‡∏ï‡πà‡∏≥
```

**Production:**
```bash
--optimization 3  # ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ ‡πÅ‡∏ï‡πà performance ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
```

### 3. Hybrid Quantization

**Use case:** Layers ‡∏ö‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å (e.g., detection head)

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á hybrid_config.txt
echo "output_layer FP16" > hybrid_config.txt
echo "bbox_head FP16" >> hybrid_config.txt

python3 universal_onnx_to_rknn.py \
    --onnx model.onnx \
    --rknn model_hybrid.rknn \
    --quantize \
    --hybrid-quant \
    --hybrid-quant-file hybrid_config.txt
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
- Accuracy ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á FP16
- Performance ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á INT8
- ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á FP16-INT8

---

## üéì Best Practices

### ‚úÖ DO

1. **‡πÉ‡∏ä‡πâ FP16 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Development**
   ```bash
   # Quick testing
   python3 universal_onnx_to_rknn.py --onnx model.onnx --rknn model.rknn
   ```

2. **‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset ‡∏ó‡∏µ‡πà‡∏î‡∏µ**
   - 500-1000 ‡∏£‡∏π‡∏õ
   - ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° use cases
   - ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å training set

3. **Verify Model**
   ```bash
   --verify  # ‡πÄ‡∏™‡∏°‡∏≠!
   ```

4. **‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Accuracy**
   - Test ONNX vs RKNN
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö mAP, F1-score

5. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ö‡∏ô Hardware ‡∏à‡∏£‡∏¥‡∏á**
   - Benchmark ‡∏ö‡∏ô RK3588
   - ‡∏ß‡∏±‡∏î FPS, Latency

### ‚ùå DON'T

1. **‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ Test Set ‡πÉ‡∏ô Dataset.txt**
   - Data leakage!

2. **‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ Optimization 0**
   - Performance ‡πÅ‡∏¢‡πà

3. **‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏° Dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö INT8**
   - Accuracy ‡∏à‡∏∞‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å

4. **‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ Relative Path**
   - ‡∏à‡∏∞‡∏´‡∏≤ file ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠

5. **‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ Dataset ‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ**
   - < 100 ‡∏£‡∏π‡∏õ ‚Üí Accuracy ‡πÅ‡∏¢‡πà

---

## üìö Workflow Example

### Complete Workflow: YOLOv8 Custom Model

#### Step 1: Export ONNX

```python
# PyTorch
from ultralytics import YOLO
model = YOLO('best.pt')
model.export(format='onnx', simplify=True)
```

#### Step 2: Prepare Dataset

```bash
python3 create_dataset_txt.py \
    -i dataset/train/images \
    -o dataset.txt \
    -n 1000
```

#### Step 3: Convert to FP16 (Development)

```bash
python3 universal_onnx_to_rknn.py \
    --onnx best.onnx \
    --rknn best_fp16.rknn \
    --verify
```

#### Step 4: Test on Hardware

```bash
# Transfer to RK3588
scp best_fp16.rknn firefly@192.168.1.100:~/models/

# Run inference
python3 npu_inference.py \
    --model best_fp16.rknn \
    --image test.jpg \
    --conf 0.25 \
    --iou 0.85
```

#### Step 5: Convert to INT8 (Production)

```bash
python3 universal_onnx_to_rknn.py \
    --onnx best.onnx \
    --rknn best_int8.rknn \
    --quantize \
    --algorithm mmse \
    --dataset dataset.txt \
    --verify
```

#### Step 6: Benchmark

```bash
# Compare FP16 vs INT8
python3 benchmark.py --model best_fp16.rknn --runs 100
python3 benchmark.py --model best_int8.rknn --runs 100
```

#### Step 7: Deploy

```bash
# Final deployment
cp best_int8.rknn /opt/models/production/
```

---

## üîó Related Documentation

- [PREPROCESSING_POSTPROCESSING_GUIDE.md](./PREPROCESSING_POSTPROCESSING_GUIDE.md) - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ Pre/Post processing
- [COMPLETE_BEGINNER_GUIDE.md](./COMPLETE_BEGINNER_GUIDE.md) - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
- [ONNX_to_RKNN_Guide.md](./ONNX_to_RKNN_Guide.md) - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ ONNX to RKNN ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

---

## ‚ùì FAQ

### Q: FP16 ‡∏Å‡∏±‡∏ö INT8 ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**A:**
| | FP16 | INT8 |
|---|------|------|
| **Accuracy** | ‚úÖ ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (99%) | ‚ö†Ô∏è ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (95-98%) |
| **Speed** | ‚ö° Baseline | ‚ö°‚ö°‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ 2-4x |
| **Size** | üì¶ Baseline | üì¶ ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50% |
| **Use case** | Development, High accuracy | Production, Real-time |

### Q: Dataset ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å Training Set ‡∏´‡∏£‡∏∑‡∏≠?

**A:** ‚úÖ ‡πÉ‡∏ä‡πà! ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å training set (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà test set)
- ‚úÖ Training set: OK
- ‚úÖ Validation set: OK  
- ‚ùå Test set: NOT OK (data leakage)

### Q: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ‡πÉ‡∏ô Dataset ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?

**A:**
- ‚úÖ **500-1000 ‡∏£‡∏π‡∏õ**: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
- ‚ö†Ô∏è 100-500 ‡∏£‡∏π‡∏õ: ‡∏û‡∏≠‡πÉ‡∏ä‡πâ
- ‚ùå < 100 ‡∏£‡∏π‡∏õ: ‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

### Q: MMSE ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ Normal ‡∏°‡∏≤‡∏Å‡πÑ‡∏´‡∏°?

**A:** ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ 2-3 ‡πÄ‡∏ó‡πà‡∏≤ ‡πÅ‡∏ï‡πà accuracy ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
- Normal: 30s
- MMSE: 60-90s
- KL Divergence: 120-180s

### Q: Hybrid Quantization ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**A:** Mix FP16 + INT8
- Layers ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‚Üí FP16 (accuracy)
- Layers ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‚Üí INT8 (speed)
- ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á accuracy ‡πÅ‡∏•‡∏∞ performance

### Q: ‡πÅ‡∏õ‡∏•‡∏á‡∏ö‡∏ô x86 ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ‡∏ö‡∏ô ARM ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°?

**A:** ‚úÖ ‡πÑ‡∏î‡πâ! ‡πÅ‡∏õ‡∏•‡∏á‡∏ö‡∏ô x86/x64 Linux ‚Üí ‡πÉ‡∏ä‡πâ‡∏ö‡∏ô RK3588 ARM

### Q: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Model ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?

**A:**
- ‚úÖ YOLOv5, YOLOv8, YOLOv10, YOLO-NAS
- ‚úÖ ResNet, MobileNet, EfficientNet
- ‚úÖ Custom models (‡∏ñ‡πâ‡∏≤ operators ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)

---

## üìû Support & Resources

### Documentation
- [RKNN-Toolkit2 Official Docs](https://github.com/rockchip-linux/rknn-toolkit2)
- [ONNX Documentation](https://onnx.ai/onnx/)

### Community
- [Rockchip NPU Forum](https://forum.radxa.com/)
- GitHub Issues

### Tools
- `create_dataset_txt.py` - Dataset creation
- `npu_inference.py` - Inference testing
- `benchmark.py` - Performance testing

---

**üìÖ Last Updated:** November 27, 2025  
**‚úçÔ∏è Author:** Firefly EC-R3588SPC Development Team  
**üîñ Version:** 1.0.0
