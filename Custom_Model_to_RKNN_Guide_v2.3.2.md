# RKNN-Toolkit2 v2.3.2 - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå

> **‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 2.3.2  
> **‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ó:** November 26, 2025  
> **‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏≥:** ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Official SDK

---

## üìë ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1. [‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° RKNN Software Stack](#‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°-rknn-software-stack)
2. [‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô v2.3.2](#‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô-v232)
3. [‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö](#‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
4. [‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á](#‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á)
5. [Operator Support (ONNX/PyTorch/Caffe/TensorFlow)](#operator-support)
6. [‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - Custom Model](#‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô---custom-model)
7. [‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î](#‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î)
8. [‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©](#‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©)
9. [‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á](#‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)

---

## ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° RKNN Software Stack

RKNN (Rockchip Neural Network) ‡πÄ‡∏õ‡πá‡∏ô SDK ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô AI Model ‡∏ö‡∏ô‡∏ä‡∏¥‡∏õ NPU ‡∏Ç‡∏≠‡∏á Rockchip ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å 3 ‡∏™‡πà‡∏ß‡∏ô:

### üîß RKNN-Toolkit2 (PC/Server)
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (ONNX/PyTorch/TensorFlow/Caffe) ‚Üí RKNN
- **‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:** Model conversion, Quantization, Inference simulation
- **‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£:** Linux x86_64, ARM64

### üì± RKNN-Toolkit-Lite2 (Edge Device)
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• RKNN ‡∏ö‡∏ô‡∏ö‡∏≠‡∏£‡πå‡∏î (Python API)
- **‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á:** ‡∏ú‡πà‡∏≤‡∏ô pip
- **‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£:** Linux ARM64

### ‚ö° RKNN Runtime (Edge Device)
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• RKNN ‡∏ö‡∏ô‡∏ö‡∏≠‡∏£‡πå‡∏î (C/C++ API)
- **‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:** ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Production
- **‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£:** Linux ARM64

### üî© RKNPU Kernel Driver
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** Interface ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Software ‚Üî NPU Hardware
- **‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤:** Open source ‡πÉ‡∏ô Rockchip kernel

---

## ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô v2.3.2

### üÜï ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏≤
| ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î |
|---------|-----------|
| **RV1126B Support** | ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡πÉ‡∏´‡∏°‡πà RV1126B |
| **Improved Einsum & Norm** | ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á operator ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Transformer |
| **Automatic Mixed Precision** | ‡πÉ‡∏ä‡πâ INT8 + FP16 ‡∏ú‡∏™‡∏°‡∏Å‡∏±‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ |
| **Graph Optimization** | ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£ optimize graph ‡∏Å‡πà‡∏≠‡∏ô convert |

### üìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤

| ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô | ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô |
|---------|---------|
| **v2.3.2** | RV1126B, Auto Mixed Precision |
| v2.3.0 | ARM64 support, W4A16 quantization (RK3576) |
| v2.2.0 | Pip installation, Python 3.12 |
| v2.1.0 | Flash Attention (RK3562/RK3576) |
| v1.6.0 | **ONNX Opset 12-19 Support** ‚≠ê |

---

## ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

### ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
- **RK3588 Series** - High-end (6 TOPS)
- **RK3576 Series** - Mid-to-High (6 TOPS)
- **RK3566/RK3568 Series** - Mid-range (1 TOPS)
- **RK3562 Series** - Entry-level
- **RV1103/RV1106** - Vision processors
- **RV1103B/RV1106B** - Vision processors (Updated)
- **RV1126B** - üÜï New in v2.3.2
- **RK2118** - Audio processors

### ‚ö†Ô∏è ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡πÄ‡∏Å‡πà‡∏≤ (‡πÉ‡∏ä‡πâ Toolkit v1)
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö **RK1808/RV1109/RV1126/RK3399Pro** ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ:
- https://github.com/airockchip/rknn-toolkit
- https://github.com/airockchip/rknpu

---

## ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

### üêç Python Version Support
```
Python 3.6, 3.7, 3.8, 3.9, 3.10, 3.11, 3.12
```

### üì¶ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ú‡πà‡∏≤‡∏ô Pip (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

```bash
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PC (x86_64)
pip install rknn-toolkit2-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PC (ARM64)
pip install rknn-toolkit2-2.3.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏≠‡∏£‡πå‡∏î (RKNN-Toolkit-Lite2)
pip install rknn_toolkit_lite2-2.3.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `cp310` ‡∏ï‡∏≤‡∏° Python version ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (cp36, cp37, cp38, cp39, cp311, cp312)

### üì• ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å Local File

```bash
cd rknn-toolkit2-2.3.2/rknn-toolkit2/packages/x86_64/
pip install rknn_toolkit2-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
```

### üîß ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ï‡∏≤‡∏° Python version
pip install -r requirements_cp310-2.3.2.txt
```

---

## Operator Support

### üîπ ONNX Operators (Opset 12-19)

**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Operators ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö:** 100+ operators

#### ‚úÖ Operators ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö

| Category | Operators |
|----------|-----------|
| **Activation** | Relu, Sigmoid, Tanh, LeakyRelu, PRelu, Elu, HardSigmoid, HardSwish, Softmax, Softplus, Mish |
| **Convolution** | Conv, ConvTranspose, DepthToSpace, SpaceToDepth |
| **Pooling** | AveragePool, MaxPool, GlobalAveragePool, GlobalMaxPool, MaxRoiPool, MaxUnpool |
| **Normalization** | BatchNormalization, InstanceNormalization, LayerNormalization, LRN, LpNormalization, MeanVarianceNormalization |
| **Arithmetic** | Add, Sub, Mul, Div, Pow, Mod |
| **Reduction** | ReduceMean, ReduceMax, ReduceMin, ReduceSum |
| **Shape** | Reshape, Flatten, Squeeze, Unsqueeze, Transpose, Concat, Split, Slice |
| **Math** | Exp, Log, Sqrt, Sin, Cos, Floor, Clip, Erf |
| **Logical** | And, Equal, Greater, GreaterOrEqual, Less, LessOrEqual, Where |
| **RNN** | LSTM, GRU (batchsize: 1) |
| **Other** | Pad, Resize (nearest/bilinear), Gather, GatherElements, ScatterND, Cast, Constant, ConstantOfShape, Dropout, Expand, Gemm, MatMul, RoiAlign, Shape, Size, ReverseSequence |

#### ‚ùå Operators ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

```
Abs, Acos, Asin, Atan, Ceil, Einsum, NonMaxSuppression, 
TopK, Loop, Scan, Range, OneHot, ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ
```

**‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡πá‡∏°:** `doc/RKNNToolKit2_OP_Support-2.3.2.md`

---

### üîπ PyTorch Operators

**‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å:** PyTorch >= 1.6.0

#### ‚úÖ Operators ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)

```python
aten::_convolution      # Conv layers
aten::adaptive_avg_pool2d
aten::add, aten::mul, aten::div
aten::batch_norm
aten::relu, aten::sigmoid, aten::tanh
aten::hardswish, aten::mish, aten::silu
aten::matmul, aten::bmm
aten::cat, aten::split
aten::reshape, aten::flatten
aten::max_pool2d, aten::avg_pool2d
aten::lstm, aten::gru
aten::layer_norm
aten::softmax
aten::transpose, aten::permute
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** PyTorch model ‡∏Ñ‡∏ß‡∏£ export ‡πÄ‡∏õ‡πá‡∏ô TorchScript (.pt) ‡∏´‡∏£‡∏∑‡∏≠ ONNX ‡∏Å‡πà‡∏≠‡∏ô

---

### üîπ Caffe Operators

**Protocol Version:** Berkeley Caffe (commit 21d0608) + Custom extensions

#### ‚úÖ Operators ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

```
BatchNorm, bn (BatchNorm+Scale), Convolution, ConvolutionDepthwise
Deconvolution, Pooling, InnerProduct, Concat, Eltwise
Relu, Relu6, PRelu, Sigmoid, TanH, Softmax
LRN, Dropout, Flatten, Reshape, Permute, Slice
Normalize, Scale, Power, Crop, Reorg
Lstm, Proposal, ROIPooling, Resize, Upsample
```

---

### üîπ TensorFlow Operators

**‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:**
- TensorFlow 1.x: v1.12 - v1.15
- TensorFlow 2.x: v2.3 - v2.5

#### ‚úÖ Operators ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

```
Add, AvgPool, MaxPool, Conv2D, DepthwiseConv2d
Div, LeakyRelu, Relu, Sigmoid, Softmax, Tanh
MatMul, Concat, Reshape, Transpose, Squeeze
Pad, Slice, Split, StridedSlice
ResizeBilinear, ResizeNearestNeighbor
DepthToSpace, SpaceToDepth
Mean, LRN, Softplus, Dropout, Flatten
```

---

### üîπ Darknet Operators

```
add, batchnormalize, concat
convolutional, depthwise_convolutional
fullconnect, leakyrelu, mish
pooling (Average/Max/Global)
route, shortcut, softmax, upsampling
```

---

## ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - Custom Model

### üéØ ‡∏Å‡∏é‡πÄ‡∏´‡∏•‡πá‡∏Å 4 ‡∏Ç‡πâ‡∏≠ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Custom Model

#### 1Ô∏è‚É£ ‡∏ï‡πâ‡∏≠‡∏á "‡∏ï‡∏±‡∏î‡∏´‡∏±‡∏ß" (Remove Post-processing)

**‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏™‡πà‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•:**
- Decode Box (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏¥‡∏Å‡∏±‡∏î x, y, w, h)
- NMS (Non-Maximum Suppression)
- Confidence Thresholding
- Class filtering

**‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥:** ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤ Feature Map (Raw output) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥ Post-processing ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ Python/C++

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å Official Code:**
```python
# rknn-toolkit2-2.3.2/examples/onnx/yolov5/test.py (line 284-315)

# 1. Inference (‡πÑ‡∏î‡πâ Raw outputs)
outputs = rknn.inference(inputs=[img2], data_format=['nhwc'])

# 2. Post-process ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å NPU
input0_data = outputs[0]  # Feature map 80x80
input1_data = outputs[1]  # Feature map 40x40
input2_data = outputs[2]  # Feature map 20x20

# 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì boxes, classes, scores ‡∏î‡πâ‡∏ß‡∏¢ Python
boxes, classes, scores = yolov5_post_process(input_data)
```

---

#### 2Ô∏è‚É£ ‡∏ï‡πâ‡∏≠‡∏á "Static Shape" (‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏á‡∏ó‡∏µ‡πà)

**‡∏´‡πâ‡∏≤‡∏°:** ‡πÉ‡∏ä‡πâ `dynamic_axes` ‡πÉ‡∏ô ONNX export

```python
# ‚ùå ‡∏ú‡∏¥‡∏î - Dynamic shape
torch.onnx.export(
    model, dummy_input, "model.onnx",
    dynamic_axes={'images': {0: 'batch', 2: 'height', 3: 'width'}}  # ‡∏´‡πâ‡∏≤‡∏°!
)

# ‚úÖ ‡∏ñ‡∏π‡∏Å - Static shape
torch.onnx.export(
    model, 
    torch.randn(1, 3, 640, 640),  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß
    "model.onnx",
    opset_version=12
    # ‡πÑ‡∏°‡πà‡∏°‡∏µ dynamic_axes
)
```

**‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•:** NPU ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≠‡∏á Memory ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö Fixed size

---

#### 3Ô∏è‚É£ ‡πÉ‡∏ä‡πâ ONNX Opset 12-19 (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 12)

```python
# ‚úÖ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ - Opset 12 (‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)
torch.onnx.export(model, dummy_input, "model.onnx", opset_version=12)

# ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ - Opset 13-19
torch.onnx.export(model, dummy_input, "model.onnx", opset_version=19)
```

**‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:** CHANGELOG v1.6.0 - "Support ONNX model of OPSET 12~19"

---

#### 4Ô∏è‚É£ ‡∏£‡∏∞‡∏ß‡∏±‡∏á "Tensor Reshape/Transpose" ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

**‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á:** ‡∏Å‡∏≤‡∏£ Reshape ‡πÄ‡∏õ‡πá‡∏ô 5D ‡∏´‡∏£‡∏∑‡∏≠ permute ‡∏°‡∏¥‡∏ï‡∏¥‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

**‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥:** ‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ NPU ‡∏™‡πà‡∏á output ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥ Reshape/Transpose ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# NPU ‡∏™‡πà‡∏á output ‡∏°‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Hardware-specific
input0_data = outputs[0]

# Reshape ‡πÅ‡∏•‡∏∞ Transpose ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å
input0_data = input0_data.reshape([3, -1] + list(input0_data.shape[-2:]))
input0_data = np.transpose(input0_data, (2, 3, 0, 1))
```

---

### üìù Export Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Custom Model

```python
import torch
import torch.nn as nn

# ========================================
# ‡∏™‡∏°‡∏°‡∏ï‡∏¥ Custom Model ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
# ========================================
class MyCustomYOLO(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = ...  # ResNet, EfficientNet, etc.
        self.neck = ...      # FPN, PANet, etc.
        self.head = nn.Sequential(
            nn.Conv2d(256, 128, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128, 85, 1)  # 85 = (x,y,w,h,conf) + 80 classes
        )
    
    def forward(self, x):
        x = self.backbone(x)
        x = self.neck(x)
        x = self.head(x)
        
        # ‚úÖ ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏™‡πà‡∏á Feature Map ‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡πÄ‡∏•‡∏¢
        # ‚ùå ‡∏≠‡∏¢‡πà‡∏≤‡∏ó‡∏≥: decode_boxes(), NMS() ‡πÉ‡∏ô‡∏ô‡∏µ‡πâ
        return x

# ========================================
# Export ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RKNN (The Golden Script)
# ========================================
def export_for_rknn():
    model = MyCustomYOLO()
    model.eval()
    
    # ‚úÖ Static Shape (1, 3, 640, 640)
    dummy_input = torch.randn(1, 3, 640, 640)
    
    torch.onnx.export(
        model,
        dummy_input,
        "custom_yolo_rknn.onnx",
        
        # ‚úÖ Opset 12 (‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
        opset_version=12,
        
        # ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ Input/Output ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        input_names=['images'],
        output_names=['output'],
        
        # ‚úÖ ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ dynamic_axes
        # dynamic_axes={'images': {0: 'batch'}}  # <-- ‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á!
        
        # ‡∏ä‡πà‡∏ß‡∏¢ Optimize constant folding
        do_constant_folding=True
    )
    
    print("‚úÖ Export ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RKNN")

if __name__ == "__main__":
    export_for_rknn()
```

---

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î

### üîπ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 1: ONNX YOLOv5 (‡πÅ‡∏ö‡∏ö Python Script)

```python
from rknn.api import RKNN
import cv2
import numpy as np

# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á RKNN object
rknn = RKNN(verbose=True)

# 2. Config preprocessing
rknn.config(
    mean_values=[[0, 0, 0]], 
    std_values=[[255, 255, 255]], 
    target_platform='rk3588'
)

# 3. Load ONNX model
rknn.load_onnx(model='yolov5s_relu.onnx')

# 4. Build (‡∏ó‡∏≥ Quantization)
rknn.build(do_quantization=True, dataset='./dataset.txt')

# 5. Export RKNN model
rknn.export_rknn('./yolov5s_relu.rknn')

# 6. Init runtime (‡∏ñ‡πâ‡∏≤‡∏à‡∏∞ inference ‡∏ö‡∏ô PC)
rknn.init_runtime()

# 7. Prepare input
img = cv2.imread('bus.jpg')
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img = cv2.resize(img, (640, 640))
img = np.expand_dims(img, 0)

# 8. Inference
outputs = rknn.inference(inputs=[img], data_format=['nhwc'])

# 9. Post-processing (‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å NPU)
boxes, classes, scores = yolov5_post_process(outputs)

# 10. Release
rknn.release()
```

---

### üîπ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 2: PyTorch ResNet18

```python
from rknn.api import RKNN
import torch
import torchvision.models as models

# 1. Export PyTorch to TorchScript
model = models.resnet18(pretrained=True)
model.eval()
trace_model = torch.jit.trace(model, torch.Tensor(1, 3, 224, 224))
trace_model.save('./resnet18.pt')

# 2. Convert to RKNN
rknn = RKNN(verbose=True)
rknn.config(
    mean_values=[123.675, 116.28, 103.53], 
    std_values=[58.395, 58.395, 58.395], 
    target_platform='rk3588'
)
rknn.load_pytorch(model='./resnet18.pt', input_size_list=[[1, 3, 224, 224]])
rknn.build(do_quantization=True, dataset='./dataset.txt')
rknn.export_rknn('./resnet18.rknn')
```

---

### üîπ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà 3: Model Config YAML (rknn_convert)

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `model_config.yml`:

```yaml
models:
    name: yolov5s_relu           # ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• output
    platform: onnx               # onnx, pytorch, tensorflow, caffe
    model_file_path: ./yolov5s_relu.onnx
    quantize: true               # ‡πÄ‡∏õ‡∏¥‡∏î Quantization
    dataset: ./dataset.txt       # Path to calibration dataset
    configs:
      quantized_dtype: asymmetric_quantized-8  # INT8 quantization
      mean_values: [0, 0, 0]
      std_values: [255, 255, 255]
      quant_img_RGB2BGR: false
      quantized_algorithm: normal  # normal, mmse
      quantized_method: channel    # channel, layer
```

**‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:**
```bash
python3 -m rknn.api.rknn_convert -t rk3588 -i ./model_config.yml -o ./
```

---

## ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©

### üîπ 1. Dynamic Shape (‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∏‡∏î Shape ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤)

```python
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∏‡∏î Input shapes ‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï
dynamic_input = [
    [[1,3,256,256]],    # Set 1
    [[1,3,160,160]],    # Set 2
    [[1,3,224,224]],    # Set 3
]

rknn.config(
    mean_values=[103.94, 116.78, 123.68],
    std_values=[58.82, 58.82, 58.82],
    target_platform='rk3588',
    dynamic_input=dynamic_input  # ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ dynamic shape
)

# Inference ‡∏î‡πâ‡∏ß‡∏¢ shape ‡∏ï‡πà‡∏≤‡∏á‡πÜ
img1 = cv2.resize(img, (224,224))
outputs1 = rknn.inference(inputs=[img1], data_format=['nhwc'])

img2 = cv2.resize(img, (160,160))
outputs2 = rknn.inference(inputs=[img2], data_format=['nhwc'])
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Dynamic ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ

---

### üîπ 2. Hybrid Quantization (INT8 + FP16)

```python
rknn.config(
    target_platform='rk3588',
    quantized_dtype='asymmetric_quantized-8',  # INT8
    hybrid_quantization_step='fp16',           # ‡πÉ‡∏ä‡πâ FP16 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö layer ‡∏ó‡∏µ‡πà sensitive
)
```

**‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå:** ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô + ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏à‡∏≤‡∏Å INT8

---

### üîπ 3. Weight Compression (‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•)

```python
rknn.config(
    target_platform='rk3588',
    optimization_level=3,        # 0=none, 1=low, 2=medium, 3=high
    weight_sharing=True,         # Share duplicate weights
    weight_compression=True,     # Compress weights (RK3588/RV1106)
)
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:** ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå .rknn ‡πÅ‡∏•‡∏∞ Memory usage

---

### üîπ 4. Multi-Core Mode (RK3588 only)

```python
rknn.init_runtime(
    core_mask=RKNN.NPU_CORE_0_1_2  # ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á 3 cores
)
```

**Options:**
- `RKNN.NPU_CORE_0` - Core 0 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- `RKNN.NPU_CORE_1` - Core 1 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- `RKNN.NPU_CORE_2` - Core 2 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- `RKNN.NPU_CORE_0_1_2` - ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á 3 cores

---

### üîπ 5. Accuracy Analysis (‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥)

```python
rknn.accuracy_analysis(
    inputs=['./test_data/input.npy'],
    output_dir='./accuracy_analysis',
    target='rk3588'
)
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:** ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Original model vs RKNN model ‡πÅ‡∏ï‡πà‡∏•‡∏∞ layer

---

### üîπ 6. Custom Operator Support

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Operator ‡∏ó‡∏µ‡πà NPU ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ CPU/GPU fallback:

```python
rknn.config(
    target_platform='rk3588',
    custom_op={
        'op_name': 'MyCustomOp',
        'op_type': 'CPU',  # CPU or GPU
        'op_lib': './libcustom_op.so'
    }
)
```

---

## ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á

### üìÑ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô SDK

| ‡πÑ‡∏ü‡∏•‡πå | ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ |
|------|---------|
| `CHANGELOG.md` | ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ó‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô |
| `README.md` | ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° SDK ‡πÅ‡∏•‡∏∞ Platform support |
| `doc/RKNNToolKit2_OP_Support-2.3.2.md` | ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Operators ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (ONNX/PyTorch/Caffe/TF/Darknet) |
| `doc/rknn_server_proxy.md` | ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ rknn_server ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Remote debugging |
| `doc/Using RKNN-ToolKit2 in WSL.md` | ‡πÉ‡∏ä‡πâ RKNN-Toolkit2 ‡∏ö‡∏ô WSL (Windows) |

### üìÅ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á

```
rknn-toolkit2/examples/
‚îú‚îÄ‚îÄ onnx/
‚îÇ   ‚îú‚îÄ‚îÄ resnet50v2/
‚îÇ   ‚îî‚îÄ‚îÄ yolov5/              # ‚≠ê ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
‚îú‚îÄ‚îÄ pytorch/
‚îÇ   ‚îú‚îÄ‚îÄ resnet18/
‚îÇ   ‚îú‚îÄ‚îÄ resnet18_qat/
‚îÇ   ‚îî‚îÄ‚îÄ yolov5/
‚îú‚îÄ‚îÄ tensorflow/
‚îÇ   ‚îú‚îÄ‚îÄ ssd_mobilenet_v1/
‚îÇ   ‚îî‚îÄ‚îÄ inception_v3_qat/
‚îú‚îÄ‚îÄ caffe/
‚îÇ   ‚îú‚îÄ‚îÄ mobilenet_v2/
‚îÇ   ‚îî‚îÄ‚îÄ vgg-ssd/
‚îú‚îÄ‚îÄ tflite/
‚îÇ   ‚îú‚îÄ‚îÄ mobilenet_v1/
‚îÇ   ‚îî‚îÄ‚îÄ mobilenet_v1_qat/
‚îú‚îÄ‚îÄ darknet/
‚îÇ   ‚îî‚îÄ‚îÄ yolov3_416x416/
‚îî‚îÄ‚îÄ functions/
    ‚îú‚îÄ‚îÄ accuracy_analysis/   # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
    ‚îú‚îÄ‚îÄ dynamic_shape/       # ‚≠ê Dynamic input shape
    ‚îú‚îÄ‚îÄ hybrid_quant/        # INT8+FP16 mixed quantization
    ‚îú‚îÄ‚îÄ multi_batch/         # Batch processing
    ‚îú‚îÄ‚îÄ custom_op/           # Custom operator
    ‚îú‚îÄ‚îÄ model_pruning/       # Model pruning
    ‚îú‚îÄ‚îÄ codegen/             # Generate C++ deployment code
    ‚îî‚îÄ‚îÄ onnx_edit/           # Edit ONNX graph
```

### üåê ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå

- **Official GitHub:** https://github.com/airockchip/rknn-toolkit2
- **RKNN Model Zoo:** https://github.com/airockchip/rknn_model_zoo
- **RKNPU2 SDK Download:** https://console.zbox.filez.com/l/I00fc3 (‡∏£‡∏´‡∏±‡∏™: rknn)
- **RKNN-LLM (Large Language Model):** https://github.com/airockchip/rknn-llm
- **Redmine (Official Support):** https://redmine.rock-chips.com

### üí¨ Community Support

- **QQ Group 1:** 1025468710 (‡πÄ‡∏ï‡πá‡∏°)
- **QQ Group 2:** 547021958 (‡πÄ‡∏ï‡πá‡∏°)
- **QQ Group 3:** 469385426 (‡πÄ‡∏ï‡πá‡∏°)
- **QQ Group 4:** 958083853 ‚úÖ

---

## üéØ ‡∏™‡∏£‡∏∏‡∏õ Checklist ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Custom Model

### ‡∏Å‡πà‡∏≠‡∏ô Export ONNX
- [ ] ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Operators ‡∏ó‡∏µ‡πà RKNN ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å OP Support List)
- [ ] ‡∏ï‡∏±‡∏î Post-processing ‡∏≠‡∏≠‡∏Å (NMS, Decode, Thresholding)
- [ ] ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏ô‡∏≤‡∏î Input ‡πÅ‡∏ö‡∏ö Static (‡πÄ‡∏ä‡πà‡∏ô 640x640)
- [ ] ‡πÉ‡∏ä‡πâ Opset 12-19 (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 12)

### Export ONNX
```python
torch.onnx.export(
    model,
    torch.randn(1, 3, 640, 640),  # ‚úÖ Static shape
    "model.onnx",
    opset_version=12,              # ‚úÖ Opset 12
    input_names=['images'],
    output_names=['output'],
    do_constant_folding=True
    # ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ dynamic_axes
)
```

### Convert to RKNN
```python
rknn = RKNN(verbose=True)
rknn.config(mean_values=[[0,0,0]], std_values=[[255,255,255]], target_platform='rk3588')
rknn.load_onnx(model='model.onnx')
rknn.build(do_quantization=True, dataset='dataset.txt')
rknn.export_rknn('model.rknn')
```

### ‡∏´‡∏•‡∏±‡∏á Convert
- [ ] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Inference ‡∏ö‡∏ô PC ‡∏î‡πâ‡∏ß‡∏¢ `rknn.init_runtime()`
- [ ] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏î‡πâ‡∏ß‡∏¢ `rknn.accuracy_analysis()`
- [ ] ‡∏ó‡∏≥ Post-processing ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å NPU
- [ ] Deploy ‡∏ö‡∏ô‡∏ö‡∏≠‡∏£‡πå‡∏î‡∏î‡πâ‡∏ß‡∏¢ RKNN Runtime (C++) ‡∏´‡∏£‡∏∑‡∏≠ Toolkit-Lite2 (Python)

---

## üìå ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á

1. **ONNX Opset:** ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 12-19 ‡πÅ‡∏ï‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 12 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
2. **Post-processing:** ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å NPU ‡πÄ‡∏™‡∏°‡∏≠ (NMS, Decode Box)
3. **Dynamic Shape:** ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∏‡∏î shapes ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤
4. **Quantization Dataset:** ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 100-500 ‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠ calibrate INT8
5. **Platform Compatibility:** RKNN-Toolkit2 ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö RKNN-Toolkit v1

---

**‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏à‡∏≤‡∏Å:** RKNN-Toolkit2 v2.3.2 Official SDK  
**‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:** November 26, 2025  
**License:** ‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç Rockchip RKNN SDK
