# Universal NPU Inference & ONNX Conversion Tools for EC-R3588SPC

‡∏ä‡∏∏‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏Å‡∏•‡∏≤‡∏á (Universal Tools) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô NPU ‡∏ö‡∏ô‡∏ö‡∏≠‡∏£‡πå‡∏î EC-R3588SPC ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ONNX ‡πÄ‡∏õ‡πá‡∏ô RKNN ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOv5/v8 ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó

## üöÄ Overview

‡∏ä‡∏∏‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô **Generic Tools** ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•:
- **Universal Inference**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö YOLO models ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (1 class ‡∏´‡∏£‡∏∑‡∏≠ 80 classes)
- **Auto-Detection**: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô class ‡πÅ‡∏•‡∏∞ output format ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- **Batch Processing**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
- **Standard Pipeline**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô YOLO (640x640, RGB)

## üìã Table of Contents

1. [‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ (Tools)](#tools)
2. [Quick Start](#quick-start)
3. [NPU Inference (‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)](#npu-inference)
4. [ONNX to RKNN Conversion (‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå)](#onnx-conversion)
5. [Performance Monitoring](#monitoring)
6. [Examples (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)](#examples)

## üõ†Ô∏è ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ {#tools}

### NPU Inference Tools (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•)
| Script | Description | Features |
|--------|-------------|----------|
| `npu_inference.py` | ‡∏£‡∏±‡∏ô inference ‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß | ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å YOLO model, Auto-NMS, Visualization |
| `batch_npu_inference.py` | ‡∏£‡∏±‡∏ô inference ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ | Parallel processing, Progress tracking |
| `npu_monitor.py` | ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ NPU | System info, Benchmarking |
| `realtime_monitor.py` | ‡∏î‡∏π‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÅ‡∏ö‡∏ö Real-time | Live CPU/Memory/NPU tracking |

### ONNX Conversion Tools (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå)
| Script | Description | Features |
|--------|-------------|----------|
| `onnx_to_rknn_converter.py` | ‡πÅ‡∏õ‡∏•‡∏á ONNX ‡πÄ‡∏õ‡πá‡∏ô RKNN | ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö FP16/INT8, Auto-Calibration |
| `batch_onnx_converter.py` | ‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏•‡∏≤‡∏¢ model ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô | Batch conversion, Summary report |

## üöÄ Quick Start {#quick-start}

### 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö

```bash
# Check NPU status
python3 npu_monitor.py info

# Start rknn_server if needed
sudo systemctl start rknn_server
```

### 2. ‡∏£‡∏±‡∏ô NPU Inference (‡πÅ‡∏ö‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)

```bash
# ‡∏£‡∏±‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ (‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏à‡∏∞ detect class ‡πÄ‡∏≠‡∏á)
python3 npu_inference.py 
  --model your_model.rknn 
  --image test_image.jpg
```

### 3. ‡πÅ‡∏õ‡∏•‡∏á ONNX ‡πÄ‡∏õ‡πá‡∏ô RKNN (‡πÅ‡∏ö‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)

```bash
# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô FP16 (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ Calibration)
python3 onnx_to_rknn_converter.py 
  --onnx your_model.onnx 
  --rknn your_model.rknn
```

## üéØ NPU Inference {#npu-inference}

‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ `npu_inference.py` ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô:
- **‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ Classes**: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ `--classes` ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏Ç Class ID (0, 1, 2...) ‡πÅ‡∏ó‡∏ô
- **Auto-Resize**: ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• (640x640) ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- **Auto-NMS**: ‡∏ï‡∏±‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ã‡πâ‡∏≥‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

### Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--model` | str | required | Path ‡πÑ‡∏ü‡∏•‡πå RKNN model |
| `--image` | str | required | Path ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û input |
| `--classes` | list | auto | ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ class names (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà‡∏à‡∏∞‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏õ‡πá‡∏ô ID) |
| `--conf` | float | 0.5 | Confidence threshold (‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à) |
| `--iou` | float | 0.45 | IoU threshold (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ã‡πâ‡∏≥) |

## üîÑ ONNX to RKNN Conversion {#onnx-conversion}

‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠ `onnx_to_rknn_converter.py` ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á 2 ‡πÇ‡∏´‡∏°‡∏î‡∏´‡∏•‡∏±‡∏Å:

### 1. FP16 Mode (‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏á‡πà‡∏≤‡∏¢)
‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
```bash
python3 onnx_to_rknn_converter.py 
  --onnx model.onnx 
  --rknn model_fp16.rknn 
  --target rk3588
```

### 2. INT8 Mode (‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)
‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á (Production) ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Quantization
```bash
python3 onnx_to_rknn_converter.py 
  --onnx model.onnx 
  --rknn model_int8.rknn 
  --quantize 
  --images ./dataset_folder/
```

## üìä Performance Monitoring {#monitoring}

### System Information
```bash
python3 npu_monitor.py info
```

### Benchmark (‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß)
```bash
python3 npu_monitor.py test 
  --model your_model.rknn 
  --image test.jpg 
  --iterations 100
```

## üí° Examples (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á) {#examples}

### Example 1: License Plate Recognition (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á)
```bash
# ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠ Class ‡πÄ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
python3 npu_inference.py 
  --model license_plate.rknn 
  --image car.jpg 
  --classes license_plate 
  --conf 0.7
```

### Example 2: Vehicle Classification (‡∏´‡∏•‡∏≤‡∏¢ Class)
```bash
# ‡∏£‡∏∞‡∏ö‡∏∏‡∏´‡∏•‡∏≤‡∏¢ Class ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤
python3 npu_inference.py 
  --model vehicle_type.rknn 
  --image traffic.jpg 
  --classes car truck bus motorcycle 
  --conf 0.4
```

### Example 3: Batch Processing (‡∏ó‡∏≥‡∏ó‡∏µ‡∏•‡∏∞‡πÄ‡∏¢‡∏≠‡∏∞‡πÜ)
```bash
# ‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
python3 batch_onnx_converter.py 
  --onnx-dir ./my_onnx_models/ 
  --output-dir ./my_rknn_models/

# ‡∏£‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏£‡∏π‡∏õ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
python3 batch_npu_inference.py 
  --model my_model.rknn 
  --input ./test_images/ 
  --output ./results/
```

## üö® Troubleshooting

### Common Issues
1. **"Unsupported operator"**: ONNX Opset ‡πÄ‡∏Å‡πà‡∏≤/‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏õ -> ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ **Opset 12** ‡∏ï‡∏≠‡∏ô export ‡∏à‡∏≤‡∏Å PyTorch
2. **"Input size mismatch"**: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏±‡∏ö 640x640 ‡πÅ‡∏ï‡πà‡∏™‡πà‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡∏≠‡∏∑‡πà‡∏ô -> ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏°‡∏µ Auto-resize ‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ
3. **"NPU timeout"**: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡πâ‡∏≠‡∏ô‡∏™‡∏π‡∏á -> ‡πÄ‡∏ä‡πá‡∏Ñ `npu_monitor.py`

---
**Note:** ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ö‡∏ô‡∏ö‡∏≠‡∏£‡πå‡∏î **EC-R3588SPC** (RK3588) ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö YOLOv5 ‡πÅ‡∏•‡∏∞ YOLOv8


## üõ†Ô∏è ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ {#tools}

### NPU Inference Tools
| Script | Description | Features |
|--------|-------------|----------|
| `npu_inference.py` | ‡∏£‡∏±‡∏ô inference ‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß | NPU acceleration, NMS, visualization |
| `batch_npu_inference.py` | ‡∏£‡∏±‡∏ô inference ‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ | Parallel processing, progress tracking |
| `npu_monitor.py` | NPU performance monitoring | System info, benchmarking |
| `realtime_monitor.py` | Real-time resource monitor | Live CPU/Memory/NPU tracking |

### ONNX Conversion Tools
| Script | Description | Features |
|--------|-------------|----------|
| `onnx_to_rknn_converter.py` | ‡πÅ‡∏õ‡∏•‡∏á ONNX ‡πÄ‡∏õ‡πá‡∏ô RKNN | FP16/INT8, quantization, testing |
| `batch_onnx_converter.py` | ‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏•‡∏≤‡∏¢ model ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô | Batch conversion, summary report |

### Documentation
| File | Description |
|------|-------------|
| `NPU_TOOLS_GUIDE.md` | ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô NPU tools |
| `ONNX_to_RKNN_Guide.md` | ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÅ‡∏õ‡∏•‡∏á ONNX ‡πÄ‡∏õ‡πá‡∏ô RKNN |
| `README_NPU_Inference.md` | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î NPU inference |

## üöÄ Quick Start {#quick-start}

### 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö

```bash
# Check NPU status
python3 npu_monitor.py info

# Start rknn_server if needed
sudo systemctl start rknn_server
```

### 2. ‡∏£‡∏±‡∏ô NPU Inference

```bash
# Basic inference
python3 npu_inference.py \
  --model model.rknn \
  --image image.jpg \
  --classes code province

# Batch processing
python3 batch_npu_inference.py \
  --model model.rknn \
  --input ./images/ \
  --classes code province
```

### 3. ‡πÅ‡∏õ‡∏•‡∏á ONNX ‡πÄ‡∏õ‡πá‡∏ô RKNN

```bash
# Single model conversion
python3 onnx_to_rknn_converter.py \
  --onnx model.onnx \
  --rknn model.rknn

# Batch conversion
python3 batch_onnx_converter.py \
  --onnx-dir ./onnx_models/ \
  --output-dir ./rknn_models/
```

## üéØ NPU Inference {#npu-inference}

### Basic Usage

```bash
# CodeProvince Detection
python3 npu_inference.py \
  --model codeprovince_best_fp32.rknn \
  --image test.jpg \
  --classes code province \
  --conf 0.5

# Vehicle Type Detection  
python3 npu_inference.py \
  --model vehicle_detection_best_fp32.rknn \
  --image car.jpg \
  --classes car truck bus motorcycle \
  --conf 0.4
```

### Batch Processing

```bash
# Process all images in directory
python3 batch_npu_inference.py \
  --model codeprovince_best_fp32.rknn \
  --input ./test_images/ \
  --output ./results/ \
  --classes code province \
  --workers 4
```

### Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--model` | str | required | Path ‡πÑ‡∏ü‡∏•‡πå RKNN model |
| `--image` | str | required | Path ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û input |
| `--classes` | list | auto | ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ class names |
| `--conf` | float | 0.5 | Confidence threshold |
| `--iou` | float | 0.45 | IoU threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NMS |
| `--output` | str | auto | Output directory |

## üîÑ ONNX to RKNN Conversion {#onnx-conversion}

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á

```bash
# FP16 Conversion (No quantization)
python3 onnx_to_rknn_converter.py \
  --onnx model.onnx \
  --rknn model_fp16.rknn \
  --target rk3588

# INT8 Conversion (With quantization)
python3 onnx_to_rknn_converter.py \
  --onnx model.onnx \
  --rknn model_int8.rknn \
  --quantize \
  --images ./calibration_images/
```

### Batch Conversion

```bash
# Convert all ONNX models
python3 batch_onnx_converter.py \
  --onnx-dir /path/to/onnx/models/ \
  --output-dir ./converted_models/ \
  --test-image test.jpg
```

### Conversion Flow

```
ONNX Model (Float32/16) 
       ‚Üì
RKNN Toolkit2 Processing:
  ‚Ä¢ Load ONNX
  ‚Ä¢ Configure (RK3588)
  ‚Ä¢ Build & Optimize  
  ‚Ä¢ Quantization (optional)
       ‚Üì
RKNN Model (FP16/INT8)
       ‚Üì
NPU Runtime (6 TOPS)
```

## üìä Performance Monitoring {#monitoring}

### System Information

```bash
# Show NPU and system info
python3 npu_monitor.py info
```

### Performance Benchmarking

```bash
# Benchmark model performance
python3 npu_monitor.py test \
  --model model.rknn \
  --image test.jpg \
  --iterations 20 \
  --output results.json
```

### Real-time Resource Monitoring

```bash
# Monitor resources during inference
python3 realtime_monitor.py \
  --model model.rknn \
  --image test.jpg \
  --interval 0.1 \
  --output detailed_usage.json
```

## üìà ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö {#results}

### NPU Performance

| Model | Type | Inference Time | FPS | NPU Usage | Memory Impact |
|-------|------|----------------|-----|-----------|---------------|
| CodeProvince (FP32) | Original | 68-86ms | 11-14 | 1.8% | +1.2% |
| CodeProvince (FP16) | Converted | 75.8ms | 13.2 | 1.9% | +1.3% |
| Vehicle Detection (FP32) | Original | 76ms | 13.1 | 1.9% | +1.3% |

### System Resources

| Resource | Baseline | During Inference | Peak | Status |
|----------|----------|------------------|------|--------|
| **CPU** | 47-54% | 51-61% (avg) | 100% (spike) | üü¢ Normal |
| **Memory** | 56.7-57.3% | +1.2-1.3% | 58.5% | üü¢ Normal |
| **NPU Freq** | 1000 MHz | 1000 MHz | 1000 MHz | üü¢ Max Speed |
| **Temperature** | 44-46¬∞C | +2.8-4.6¬∞C | 48-52¬∞C | üü¢ Normal |

### ONNX Conversion Results

| Model | ONNX‚ÜíRKNN Size | Time | Status | Performance |
|-------|----------------|------|---------|-------------|
| codeprovince_best | ‚Üí15.1MB | 9.0s | ‚úÖ Success | Same as original |
| license_plate_model | ‚Üí46.5MB | 16.5s | ‚úÖ Success | Optimized |
| vehicle_detection_best | ‚Üí15.2MB | 8.7s | ‚úÖ Success | Same as original |

**Conversion Success Rate**: 5/5 (100%)

## üîß Configuration Examples

### Model-Specific Configurations

```bash
# CodeProvince Detection (2 classes)
python3 npu_inference.py \
  --model codeprovince_best_fp32.rknn \
  --image license_plate.jpg \
  --classes code province \
  --conf 0.6 \
  --iou 0.4

# License Plate Detection  
python3 npu_inference.py \
  --model license_plate_model.rknn \
  --image car_image.jpg \
  --classes license_plate \
  --conf 0.7

# Vehicle Type Classification (7 classes)
python3 npu_inference.py \
  --model vehicle_detection_best_fp32.rknn \
  --image traffic.jpg \
  --classes car truck bus motorcycle bicycle motorbike van \
  --conf 0.4
```

### Normalization Settings

```bash
# Default (0-255 input)
--mean 0 0 0 --std 255 255 255

# ImageNet normalization
--mean 123.675 116.28 103.53 --std 58.395 57.12 57.375
```

## üö® Troubleshooting {#troubleshooting}

### NPU Issues

```bash
# RKNN server not running
sudo systemctl start rknn_server
sudo systemctl enable rknn_server

# Check NPU devices
ls -la /dev/rknpu*

# Check NPU frequency
cat /sys/class/devfreq/fdab0000.npu/cur_freq
```

### Memory Issues

```bash
# Check system memory
free -h
python3 npu_monitor.py info

# Monitor during inference
python3 realtime_monitor.py --model model.rknn --image test.jpg
```

### Performance Issues

```bash
# Set NPU to performance mode
echo performance | sudo tee /sys/class/devfreq/fdab0000.npu/governor

# Check thermal throttling
python3 npu_monitor.py info
```

### Model Conversion Issues

```bash
# Check ONNX model validity
python3 -c "import onnx; onnx.checker.check_model(onnx.load('model.onnx'))"

# Test converted model
python3 onnx_to_rknn_converter.py --rknn model.rknn --test --image test.jpg
```

## üí° Best Practices

### Performance Optimization

1. **NPU Governor**: ‡πÉ‡∏ä‡πâ `performance` mode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö consistent performance
2. **Batch Processing**: ‡πÉ‡∏ä‡πâ parallel workers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ  
3. **Model Selection**: FP16 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö accuracy, INT8 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö speed
4. **Input Size**: 640x640 optimal ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö YOLO models

### Model Preparation

```python
# Export ONNX with optimal settings
torch.onnx.export(
    model, dummy_input, "model.onnx",
    opset_version=11,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes=None  # Fixed input size
)
```

### Calibration Dataset

- ‡πÉ‡∏ä‡πâ representative images (‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ training data)
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 50-200 ‡∏£‡∏π‡∏õ
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î 640x640
- ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÉ‡∏ô‡πÅ‡∏™‡∏á/‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á/‡∏™‡∏µ

## üéØ Use Cases

### 1. License Plate Recognition Pipeline

```bash
# Step 1: Detect license plates
python3 npu_inference.py \
  --model license_plate_model.rknn \
  --image car.jpg \
  --classes license_plate \
  --conf 0.7

# Step 2: Extract code/province
python3 npu_inference.py \
  --model codeprovince_model.rknn \
  --image cropped_plate.jpg \
  --classes code province \
  --conf 0.6
```

### 2. Traffic Monitoring

```bash
# Batch process traffic camera footage
python3 batch_npu_inference.py \
  --model vehicle_detection_best.rknn \
  --input ./traffic_images/ \
  --output ./traffic_results/ \
  --classes car truck bus motorcycle \
  --workers 4 \
  --conf 0.4
```

### 3. Model Development Workflow

```bash
# Step 1: Convert ONNX to RKNN
python3 onnx_to_rknn_converter.py \
  --onnx new_model.onnx \
  --rknn new_model.rknn

# Step 2: Test performance  
python3 npu_monitor.py test \
  --model new_model.rknn \
  --image test.jpg \
  --iterations 50

# Step 3: Validate accuracy
python3 batch_npu_inference.py \
  --model new_model.rknn \
  --input ./validation_set/ \
  --output ./validation_results/
```

## üìö Additional Resources

### Documentation Files
- `NPU_TOOLS_GUIDE.md` - Detailed usage guide
- `ONNX_to_RKNN_Guide.md` - Conversion guide
- `README_NPU_Inference.md` - Inference details

### Example Outputs
- `./npu_results/` - Inference results with bounding boxes
- `./batch_results/` - Batch processing summaries  
- `./converted_models/` - Converted RKNN models
- `conversion_summary.txt` - Conversion statistics
- `batch_summary.txt` - Batch processing statistics

### Hardware Requirements
- **Platform**: EC-R3588SPC with RK3588 SoC
- **NPU**: 6 TOPS @ 1000 MHz
- **Memory**: 8+ GB RAM recommended  
- **Storage**: SSD recommended for model loading
- **OS**: Ubuntu 20.04+ with RKNN Runtime

### Software Dependencies
- **RKNN Toolkit2**: v2.3.0+
- **Python**: 3.8+
- **OpenCV**: 4.4+
- **NumPy**: 1.17+
- **rknn_server**: Running and enabled

## üéâ Summary

### ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö NPU:
- ‚úÖ **NPU Inference**: Fast, efficient object detection
- ‚úÖ **ONNX Conversion**: Seamless model deployment  
- ‚úÖ **Performance Monitoring**: Real-time resource tracking
- ‚úÖ **Batch Processing**: Scale to multiple images/models
- ‚úÖ **Documentation**: Complete guides and examples

### Key Benefits:
- üöÄ **6 TOPS Performance** on RK3588 NPU
- ‚ö° **13+ FPS** inference speed  
- üíæ **Low Memory Usage** (+1-2% during inference)
- üå°Ô∏è **Thermal Efficient** (+2-4¬∞C temperature rise)
- üìä **100% Success Rate** in ONNX‚ÜíRKNN conversion

**Ready for Production**: Deploy your YOLO models on NPU with confidence! üéØ

---

## üìû Support

For issues or questions:
1. Check `Troubleshooting` section above
2. Review log outputs from monitoring tools
3. Validate model format and requirements  
4. Test with provided example models first

**Happy NPU Computing!** üöÄ